{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae580f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, PowerTransformer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "Postures = pd.read_csv(\"Postures.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad08a3",
   "metadata": {},
   "source": [
    "# 1) Processing the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f563055-6902-49bf-8c0d-f1f9cab49677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of missing values in column X3: 0.88%\n",
      "Proportion of missing values in column Y3: 0.88%\n",
      "Proportion of missing values in column Z3: 0.88%\n",
      "Proportion of missing values in column X4: 4.0%\n",
      "Proportion of missing values in column Y4: 4.0%\n",
      "Proportion of missing values in column Z4: 4.0%\n",
      "Proportion of missing values in column X5: 16.68%\n",
      "Proportion of missing values in column Y5: 16.68%\n",
      "Proportion of missing values in column Z5: 16.68%\n",
      "Proportion of missing values in column X6: 33.1%\n",
      "Proportion of missing values in column Y6: 33.1%\n",
      "Proportion of missing values in column Z6: 33.1%\n",
      "Proportion of missing values in column X7: 50.13%\n",
      "Proportion of missing values in column Y7: 50.13%\n",
      "Proportion of missing values in column Z7: 50.13%\n",
      "Proportion of missing values in column X8: 60.86%\n",
      "Proportion of missing values in column Y8: 60.86%\n",
      "Proportion of missing values in column Z8: 60.86%\n",
      "Proportion of missing values in column X9: 69.31%\n",
      "Proportion of missing values in column Y9: 69.31%\n",
      "Proportion of missing values in column Z9: 69.31%\n",
      "Proportion of missing values in column X10: 81.11%\n",
      "Proportion of missing values in column Y10: 81.11%\n",
      "Proportion of missing values in column Z10: 81.11%\n",
      "Proportion of missing values in column X11: 99.96%\n",
      "Proportion of missing values in column Y11: 99.96%\n",
      "Proportion of missing values in column Z11: 99.96%\n"
     ]
    }
   ],
   "source": [
    "# Eliminate first instance of Postures (all 0's) \n",
    "df = Postures.iloc[1:]\n",
    "\n",
    "for col in df.columns:\n",
    "    proportion = (df[col] == '?').mean()*100\n",
    "    if proportion > 0:\n",
    "        print(f'Proportion of missing values in column {col}: {round(proportion,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51b632e-8132-4b0f-85bf-3525bb2a9025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing the variables with a proportion of missing values more than 80% \n",
    "for col in df.columns:\n",
    "    proportion = (df[col] == '?').mean()*100\n",
    "    if proportion > 80:\n",
    "        df=df.drop(col, axis=1)\n",
    "        \n",
    "# Replace all '?' to NaN, so that the values are valid for Imputation\n",
    "for col in df.columns:\n",
    "    df.loc[df[col] == '?', col] = np.nan\n",
    "        \n",
    "X= df.drop(columns =[ 'Class' ]) \n",
    "y=df['Class']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66983aa8-1e1e-4379-be24-f2bbfbeea3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Divide the whole Set into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb576599",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instatiate a Simple Imputater\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    \n",
    "# Acquire a new DataFrame with Imputated Values\n",
    "imputer.fit(X_train)\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test  = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b02f6d-c6c1-4dec-9a0f-5db60e41b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler   = PowerTransformer()\n",
    "scaler.fit(X_train)\n",
    "Xt_train = scaler.transform(X_train)\n",
    "Xt_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bb377",
   "metadata": {},
   "source": [
    "# 2) Tree Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5818bd4f-0a49-4f94-8f79-a28bfc555da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Precision is:  0.9616\n",
      "The Recall is:  0.9616\n",
      "The F1 score is:  0.9616\n",
      "The Matthews correlation coefficient is:  0.9520\n",
      "\n",
      "This is the Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>3506</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>3995</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>3537</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>3691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4\n",
       "0  4046     5    13     2     6\n",
       "1     9  3506    14    24   159\n",
       "2    28    11  3995    60    21\n",
       "3    11    32    85  3537    39\n",
       "4     4   149    23    54  3691"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Decision Tree Model with the data\n",
    "tree_mdl = DecisionTreeClassifier()\n",
    "tree_mdl.fit(Xt_train, y_train)\n",
    "preds = tree_mdl.predict(Xt_test)\n",
    "\n",
    "# Present the results\n",
    "print(\"The Precision is: %7.4f\" % precision_score(y_test, preds,average='micro'))\n",
    "print(\"The Recall is: %7.4f\"    % recall_score(y_test, preds,average='micro'))\n",
    "print(\"The F1 score is: %7.4f\"  % f1_score(y_test, preds,average='micro'))\n",
    "print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, preds))\n",
    "print()\n",
    "print(\"This is the Confusion Matrix\")\n",
    "pd.DataFrame(confusion_matrix(y_test, preds))\n",
    "\n",
    "# Maybe should try with different Hyperparameters (split, leaf, criterion, depth, etc.)\n",
    "# Look into 'TP03' for better data evaluation and ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29e0ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3) Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a255c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bias is:  2.983660856055044\n",
      "The other parameters are: \n",
      "\t B1 ->     0.019\n",
      "\t B2 ->     0.179\n",
      "\t B3 ->     0.149\n",
      "\t B4 ->     0.076\n",
      "\t B5 ->     0.096\n",
      "\t B6 ->     0.186\n",
      "\t B7 ->     0.055\n",
      "\t B8 ->     0.053\n",
      "\t B9 ->     0.205\n",
      "\t B10 ->     0.020\n",
      "\t B11 ->     0.052\n",
      "\t B12 ->     0.221\n",
      "\t B13 ->    -0.031\n",
      "\t B14 ->     0.052\n",
      "\t B15 ->     0.234\n",
      "\t B16 ->    -0.083\n",
      "\t B17 ->     0.003\n",
      "\t B18 ->     0.230\n",
      "\t B19 ->    -0.176\n",
      "\t B20 ->    -0.048\n",
      "\t B21 ->     0.236\n",
      "\t B22 ->    -0.300\n",
      "\t B23 ->    -0.105\n",
      "\t B24 ->     0.182\n",
      "\t B25 ->    -0.273\n",
      "\t B26 ->    -0.059\n",
      "\t B27 ->     0.235\n",
      "\t B28 ->    -0.180\n",
      "\t B29 ->    -0.008\n",
      "\t B30 ->     0.256\n",
      "\t B31 ->    -0.125\n"
     ]
    }
   ],
   "source": [
    "# Create a Linear Regression Model with the data\n",
    "reg = LinearRegression().fit(Xt_train, y_train)\n",
    "\n",
    "# Present the Biases\n",
    "print(\"The bias is: \",  reg.intercept_)\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(reg.coef_):\n",
    "    print(\"\\t B%d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc210c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHACAYAAACVhTgAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABUsklEQVR4nO3deXhU9d3//9eZZDJJyEIWQoJsAUQ2kSUqQaFSZREvqtWuiIKoLd6o1dwUBFuBumBb+ytaW1CKonJz2/qNWqwRSZcAFpC9N7JZIaxJiCGQCVkmk8z8/sCMZD0zkGQmmefjunLB+cznnM/7nPc5k3nnLGO43W63AAAAAABNsvg7AAAAAAAIdBROAAAAAGCCwgkAAAAATFA4AQAAAIAJCicAAAAAMEHhBAAAAAAmKJwAAAAAwASFEwAAAACYCPV3AG3N5XIpLy9P0dHRMgzD3+EAAAAA8BO3263S0lJ169ZNFkvz55SCrnDKy8tTjx49/B0GAAAAgABx4sQJde/evdk+QVc4RUdHS7qwcWJiYvwcDVqC0+nU+vXrNWHCBFmtVn+HgzZAzoMPOQ8+5Dz4kPPgEwg5t9vt6tGjh6dGaE7QFU61l+fFxMRQOHUQTqdTkZGRiomJ4Y02SJDz4EPOgw85Dz7kPPgEUs69uYWHh0MAAAAAgAkKJwAAAAAwQeEEAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGCCwgkAAAAATFA4AQAAAICJUH8HAABArRqXW9tyi1VYWqmk6HBdlxqvEIv5t7m3F96uny/9th4+oy1HiiQZSu+boGt7x2t7brG2HCmSW1LniDAlRoUpOTaiwXLqjzOyV5x2HjurwtJKJUbZJLdUVOZQYiebql0uvbfrpE6eq1T3uAjdfk03/ef0eX167IwKzlWqqtolwzDUP7mTrr4iTl2ibCosrdTGzwuVX1KpSFuo+iZGKSU2XGfKKrV+f6EqnDWSS6pxS66vYjIkuSXZQtz61XXSDUuyVeq88IGl2u2Wo/rrvpJkNerOj/arNudDFn0sR03HOe79KTYiRFFhVvWMD1dcZJj2nipRYWmVXC63QiySxSKFhYQoJjxUoSEW2Sur1SksRKEhFlXXuGQLC9GInnEa2TNO9spqxUWG6UxZlYrOV2rfKbsiwkLUNcama7p31tlyp/bn21Va6ZTklmFYFG0L1Z0jumt0v0TPe09VtUtvbTmqY8Xl6h1nU4J/N5FP/Fo4LVq0SIsXL67T1rVrVxUUFDQ5z4YNG5SRkaF9+/apW7dumjt3rmbNmtXaoQIAWtm6z/K1+IP9yi+p9LSlxIZr4ZRBuvmqRD9G1jKaW79JQ1Iuqd8T7+7VuXKnp+3lf37hKTwac/FyGhvHYkiupma+yI5jZ/X+nrxGX/u88Lz++n+nG31tX16p6bLrD1/icDX7IdrpRbxAsCqpqFFJRY1OXXSc13LWSKqRyp01OldZ42kvKnPW6ff56TK9vf1ks+Os/vREk6+9tydPncJC9JvvXaPdx89qxaZcz/tMbbH8/60/qHm3Xe39ivmJ3y/VGzx4sPLz8z0/e/fubbJvbm6uJk+erDFjxmj37t1asGCBHn30UWVmZrZhxACAlrbus3w9tHpXnQ/xklRQUqmHVu/S3w40/kG8vTBbv3Wf5fvcb9bqXXWKplrN1RH5Xy1nSdb+RsfxpmgCAF+VVdVo1updemVjbqPvM69tPqYlWfvbPjAf+b1wCg0NVXJysuenS5cuTfZdvny5evbsqaVLl2rgwIF64IEHNHPmTL3wwgttGDEAoCXVuNxa/MH+Rj/w17Y9/9HBtgypRXmzfos/2K+qapfX/Rat3XfJ8bglrdiU22yBBQBtbcWmXFVVB/ZFt36/x+k///mPunXrJpvNpuuvv17PPfec+vTp02jfLVu2aMKECXXaJk6cqJUrV8rpdMpqtTaYx+FwyOFweKbtdrskyel0yuls+Jc6tD+1eSSfwYOcdyzbcotVfL5CtpCm+5w9XyGpfebcm/UrPl+h1ZsPe93vbFlls/06ApvFXedfdHzkPPjUz/nqzYd1T3rvNo3Bl98rhtvt9tve+dFHH6m8vFz9+/fX6dOn9cwzz+jgwYPat2+fEhIa3irWv39/zZgxQwsWLPC0bd68WTfccIPy8vKUkpLSYJ7G7qOSpDVr1igyMrJlVwgAAABAu1FeXq6pU6eqpKREMTExzfb16xmnW2+91fP/q6++Wunp6erbt6/eeOMNZWRkNDqPYdS9QbS27qvfXmv+/Pl1lmW329WjRw9NmDDBdOOgfXA6ncrOztb48eMbPeuIjoecdyzbcos1843tzfaxWdx6Os3VLnPuzfpJ0ryJV+mXHx9qsX7tXW3Of77DIoeLJ6wFA3IefOrnfN7Eq9r8jFPt1Wje8Pulehfr1KmTrr76av3nP/9p9PXk5OQGT9wrLCxUaGhoo2eoJMlms8lmszVot1qt7e6XL5pHToMPOe8YRvVLUnxUhApKKhu978aQlBwTLqmsXebcq/WLDde00X214l/Hver36ifHVGB3NNLLOxZDcrubf5BEoHC4DB5NHWTIefBxuAw5XYamje4ra2jbPoLBl98pfn84xMUcDocOHDjQ6CV3kpSenq7s7Ow6bevXr1daWlq7+0UKALggxGJo4ZRBki4UBxernX7i1gFtGlNL8mb9Fk4ZpLBQi9f9Fn1r8CXHY0h6cExqo+MAgL88OCZVYW1cNPnKr9HNmTNHGzZsUG5urj799FN95zvfkd1u1/Tp0yVduMzu3nvv9fSfNWuWjh07poyMDB04cECvvfaaVq5cqTlz5vhrFQAALWDSkBQtmzZCybHhddqTY8O1bNoI3TKwq58iaxlm61f7/Uy+9Fs+bYQ6Rzb8o2FzxVDKV8uZP3lQo+N0oO8aBhBAOtlCtHzaCP14bGqj7zMzR/fS/MmD2j4wH/n1Ur2TJ0/qhz/8oYqKitSlSxeNGjVKW7duVa9evSRJ+fn5On78uKd/amqqsrKy9Pjjj+v3v/+9unXrppdeekl33XWXv1YBANBCJg1J0fhBydqWW6zC0kolRYfrutR4hViMdvk0vfqaW7/L6bf18BltOVIkyVB63wRd2zte23OLteVIkdySOkeEKTEqTMmxEXWW09g4I3vFaeexsyosrVRilE1yS0VlDiV2sqna5dJ7u07q5LlKdY+L0O3XdNN/Tp/Xp8fOqOBcpaqqXTIMQ/2TO+nqK+LUJcqmwtJKbfy8UPkllYq0hapvYpRSYsN1pqxS6/cXqsJZI7mkGrdU+xDi+l/gG2uzqNR54QNLtdstR/XXfSXJatSdH8DXYiNCFBVmVc/4cMVFhmnvqRIVllbJ5XIrxCJZLFJYSIhiwkMVGmKRvbJancJCFBpiUXWNS7awEI3oGaeRPeNkr6xWXGSYzpRVqeh8pfadsisiLERdY2y6pntnnS13an++XaWVTkluGYZF0bZQ3Tmiu0b3S1SIxdCkISn67wkD9NaWozpWXK7ecTbp7H5lTGgfVxX49al6/mC32xUbG+vVkzPQPjidTmVlZWny5MlcshkkyHnwIefBh5wHH3IefAIh577UBoF9ISEAAAAABAAKJwAAAAAwQeEEAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGCCwgkAAAAATFA4AQAAAIAJCicAAAAAMEHhBAAAAAAmKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABggsIJAAAAAExQOAEAAACACQonAAAAADBB4QQAAAAAJiicAAAAAMAEhRMAAAAAmKBwAgAAAAATFE4AAAAAYILCCQAAAABMUDgBAAAAgAkKJwAAAAAwQeEEAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGCCwgkAAAAATFA4AQAAAICJgCmclixZIsMw9NhjjzXZJycnR4ZhNPg5ePBg2wUKAAAAIOiE+jsASdq+fbteffVVDR061Kv+hw4dUkxMjGe6S5curRUaAAAAAPj/jNP58+d19913a8WKFYqLi/NqnqSkJCUnJ3t+QkJCWjlKAAAAAMHM72ecZs+erdtuu0233HKLnnnmGa/mGT58uCorKzVo0CD97Gc/07hx45rs63A45HA4PNN2u12S5HQ65XQ6Ly94BITaPJLP4EHOgw85Dz7kPPiQ8+ATCDn3ZWy/Fk5vv/22du3ape3bt3vVPyUlRa+++qpGjhwph8Oht956SzfffLNycnI0duzYRudZsmSJFi9e3KB9/fr1ioyMvKz4EViys7P9HQLaGDkPPuQ8+JDz4EPOg48/c15eXu51X8PtdrtbMZYmnThxQmlpaVq/fr2uueYaSdJNN92kYcOGaenSpV4vZ8qUKTIMQ2vXrm309cbOOPXo0UNFRUV17pNC++V0OpWdna3x48fLarX6Oxy0AXIefMh58CHnwYecB59AyLndbldiYqJKSkpMawO/nXHauXOnCgsLNXLkSE9bTU2NNm7cqJdfflkOh8Ore5dGjRql1atXN/m6zWaTzWZr0G61WjkoOxhyGnzIefAh58GHnAcfch58/JlzX8b1W+F08803a+/evXXa7rvvPg0YMEDz5s3z+oEPu3fvVkpKSmuECAAAAACS/Fg4RUdHa8iQIXXaOnXqpISEBE/7/PnzderUKb355puSpKVLl6p3794aPHiwqqqqtHr1amVmZiozM7PN4wcAAAAQPPz+VL3m5Ofn6/jx457pqqoqzZkzR6dOnVJERIQGDx6sDz/8UJMnT/ZjlAAAAAA6uoAqnHJycupMr1q1qs703LlzNXfu3LYLCAAAAAAUAF+ACwAAAACBjsIJAAAAAExQOAEAAACACQonAAAAADBB4QQAAAAAJiicAAAAAMAEhRMAAAAAmKBwAgAAAAATFE4AAAAAYILCCQAAAABMUDgBAAAAgAkKJwAAAAAwQeEEAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGCCwgkAAAAATFA4AQAAAIAJCicAAAAAMEHhBAAAAAAmKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABggsIJAAAAAExQOAEAAACACQonAAAAADBB4QQAAAAAJiicAAAAAMAEhRMAAAAAmKBwAgAAAAATof4OoNaSJUu0YMEC/eQnP9HSpUub7LdhwwZlZGRo37596tatm+bOnatZs2a1XaAA0ApqXG5tyy1WYWmlEqNsklsqLK1UcVmV4qNsSo4J13Wp8QqxGHX6JkV/3Q5z3m67qmqX3tpyVMeKy9UrPlL3pPdWWKjFp2W0dEy+LqPG5fasQ4+4SPVPitK2Y8U6dbZCbrdbV8RFKD01UTKkT3OLJbmV3idRI3rFac2nxzzzDUiOVnF5lWe/PG2v1I5jZ3Qw367CUqfCQw3ZrBZ1ibbpbFmVjhdXqKrarcgwiywWqajUqZpL2C62ELd+dZ00ZNHHctSwfwcDb3NufPUTYpFiwkNkCw1RRbVbkVaLhveM05BusTpX7tTevBJFhoXoutQETR/99TEMXKqAKJy2b9+uV199VUOHDm22X25uriZPnqwHH3xQq1ev1r/+9S/913/9l7p06aK77rqrjaIFgJa17rN8Lf5gv/JLKpvtlxIbrm9dk6K1/86v0zclNlwLpwzSpCEprR1qu9bYdm5s2y3J2q8Vm3Llcn8977NZB/TgmFQN7xnn1TJaOiZflxEZFqIKZ43c7mZmlPSHnCN1pl/+52Hvg68v/3ydyTLnpZRLgDn3Vz8ul3SmvEb6qjQ/K+nU3gL9dW9Bnf7ZBwr13EcH9KMxqZo/eVBbh4sOxO+l9/nz53X33XdrxYoViouLa7bv8uXL1bNnTy1dulQDBw7UAw88oJkzZ+qFF15oo2gBoGWt+yxfD63eZVo0SVJ+SaVe2ZjboG9BSaUeWr1L6z7Lb60w272mtnP9bbcka79e2Vi3aJIkl1t6ZWOuZnmxjJaO6VKWUV5lXjQBwcT91TG8JGu/v0NBO+b3wmn27Nm67bbbdMstt5j23bJliyZMmFCnbeLEidqxY4ecTmdrhQgAraLG5dbiD/brcj/f1s6/+IP9qqn/iR/NbueLt11FVY1WbMr1efmXsv29jam55bXU/gMEkxWbclVV7fJ3GGin/Hqp3ttvv61du3Zp+/btXvUvKChQ165d67R17dpV1dXVKioqUkpKw8saHA6HHA6HZ9put0uSnE4nxVYHUZtH8hk8OkrOt+UWq/h8hWwhLbO84vMV2vpFoa5LjW+ZBQaQy8m5N9u5+HyFns/6TFbLpZchvmx/b2Nqbnktvf8EGttXubBdRk7QvrRVzldvPqx70nu36hjwTiD8PvdlbMPt9s/J/BMnTigtLU3r16/XNddcI0m66aabNGzYsCYfDtG/f3/dd999mj9/vqftX//6l2688Ubl5+crOTm5wTyLFi3S4sWLG7SvWbNGkZGRLbMyAAAAANqd8vJyTZ06VSUlJYqJiWm2r98Kp/fff1/f/va3FRLy9Z/KampqZBiGLBaLHA5HndckaezYsRo+fLhefPFFT9t7772n733veyovL5fVam0wTmNnnHr06KGioiLTjYP2wel0Kjs7W+PHj290H0DH01Fyvi23WDPf8O6Mu7dem35thz3jdKk593Y7/+DaHnp7+4lLDVGS99vf25iaW15r7D+BxGZx6+k0l36+wyKHi6fqBYO2yvm8iVdxxilABMLvc7vdrsTERK8KJ79dqnfzzTdr7969ddruu+8+DRgwQPPmzWtQNElSenq6Pvjggzpt69evV1paWpMb22azyWazNWi3Wq3t+gMXGiKnwae953xUvyTFR0WooKTysu9TMSQlx4ZrVL+kDv1o8kvJudl2rt12T0weorc+PdngwRDe8HX7extTc8tryf0nkDlcBo8jDzKtmXOLIU0b3VdWHk0eUPz5+9yXcf2210RHR2vIkCF1fjp16qSEhAQNGTJEkjR//nzde++9nnlmzZqlY8eOKSMjQwcOHNBrr72mlStXas6cOf5aDQC4ZCEWQwunXHg07uV8RKidd+GUQR26aLpUzW3ni7ddRFiIHhyTarq85pbh7fb3NqbmltdS+w8QTB4ck8r3OeGSBfSek5+fr+PHj3umU1NTlZWVpZycHA0bNkxPP/20XnrpJb7DCUC7NWlIipZNG6Hk2HDTvimx4frx2FSl1OubHBuuZdNG8D1OzWhqO9ffdvMnD9KPx6aqfr1iMaQfj03Vci+W0dIxXcoyIsNCZFBNAR7GV8cw3+OEyxEQX4BbKycnp870qlWrGvT5xje+oV27drVNQADQBiYNSdH4QcnalluswtJKJUbZJLdUWFqp4rIqxUfZlBwTrutS4xViMTR30kBP36Tor9vRvPrbualtN3/yIP33hAF6a8tRHSsuV6/4SN2T3tvzV2pvltHSMV3KMmpcbs869IiLVP+kKG07VqxTZyvkdrt1RVyE0lMTJUP6NLdYklvpfRI1olec1nx6zDPfgORoFZdXefbL0/ZK7Th2Rgfz7SosdSo81JDNalGXaJvOllXpeHGFqqrdigyzyGKRikqd4qtw0ZKMr35CLFJMeIhsoSGqqHYr0mrR8J5xGtItVufKndqbV6LIsBBdl5qg6aN7c6YJly2gCicACFYhFkPpfRNavC/q8nbbhYVadP+YPpe1jJaOyddlhFiMBuvwjQFJjc4/pn+XOtNNrXutO0d2v4QofeN0OpWVlaXPFk1s1/cywnvkHIGO0hsAAAAATFA4AQAAAIAJCicAAAAAMEHhBAAAAAAmKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABggsIJAAAAAExQOAEAAACACQonAAAAADBB4QQAAAAAJiicAAAAAMAEhRMAAAAAmKBwAgAAAAATFE4AAAAAYILCCQAAAABMUDgBAAAAgAkKJwAAAAAwQeEEAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGCCwgkAAAAATFA4AQAAAIAJCicAAAAAMEHhBAAAAAAmKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABgwq+F07JlyzR06FDFxMQoJiZG6enp+uijj5rsn5OTI8MwGvwcPHiwDaMGAAAAEGxC/Tl49+7d9fzzz6tfv36SpDfeeEO33367du/ercGDBzc536FDhxQTE+OZ7tKlS6vHCgAAACB4+bVwmjJlSp3pZ599VsuWLdPWrVubLZySkpLUuXPnVo4OAAAAAC7wa+F0sZqaGr3zzjsqKytTenp6s32HDx+uyspKDRo0SD/72c80bty4Jvs6HA45HA7PtN1ulyQ5nU45nc6WCR5+VZtH8hk8yHnwIefBh5wHH3IefAIh576MbbjdbncrxmJq7969Sk9PV2VlpaKiorRmzRpNnjy50b6HDh3Sxo0bNXLkSDkcDr311ltavny5cnJyNHbs2EbnWbRokRYvXtygfc2aNYqMjGzRdQEAAADQfpSXl2vq1KkqKSmpcytQY/xeOFVVVen48eM6d+6cMjMz9cc//lEbNmzQoEGDvJp/ypQpMgxDa9eubfT1xs449ejRQ0VFRaYbB+2D0+lUdna2xo8fL6vV6u9w0AbIefAh58GHnAcfch58AiHndrtdiYmJXhVOfr9ULywszPNwiLS0NG3fvl0vvviiXnnlFa/mHzVqlFavXt3k6zabTTabrUG71WrloOxgyGnwIefBh5wHH3IefMh58PFnzn0ZN+C+x8ntdtc5Q2Rm9+7dSklJacWIAAAAAAQ7v55xWrBggW699Vb16NFDpaWlevvtt5WTk6N169ZJkubPn69Tp07pzTfflCQtXbpUvXv31uDBg1VVVaXVq1crMzNTmZmZ/lwNAAAAAB2cXwun06dP65577lF+fr5iY2M1dOhQrVu3TuPHj5ck5efn6/jx457+VVVVmjNnjk6dOqWIiAgNHjxYH374YZMPkwAAAACAluDXwmnlypXNvr5q1ao603PnztXcuXNbMSIAAAAAaMjne5xmzpyp0tLSBu1lZWWaOXNmiwQFAAAAAIHE58LpjTfeUEVFRYP2iooKz71IAAAAANCReH2pnt1ul9vtltvtVmlpqcLDwz2v1dTUKCsrS0lJSa0SJAAAAAD4k9eFU+fOnWUYhgzDUP/+/Ru8bhiGFi9e3KLBAQAAAEAg8Lpw+uc//ym3261vfvObyszMVHx8vOe1sLAw9erVS926dWuVIAEAAADAn7wunL7xjW9IknJzc9WzZ08ZhtFqQQEAAABAIPH54RC9evXSJ598omnTpmn06NE6deqUJOmtt97SJ5980uIBAgAAAIC/+Vw4ZWZmauLEiYqIiNCuXbvkcDgkSaWlpXruuedaPEAAAAAA8DefC6dnnnlGy5cv14oVK2S1Wj3to0eP1q5du1o0OAAAAAAIBD4XTocOHdLYsWMbtMfExOjcuXMtERMAAAAABBSfC6eUlBR98cUXDdo/+eQT9enTp0WCAgAAAIBA4nPh9OMf/1g/+clP9Omnn8owDOXl5el//ud/NGfOHP3Xf/1Xa8QIAAAAAH7l9ePIa82dO1clJSUaN26cKisrNXbsWNlsNs2ZM0cPP/xwa8QIAAAAAH7lc+EkSc8++6yefPJJ7d+/Xy6XS4MGDVJUVFRLxwYAAAAAAcHnS/VqRUZGKi0tTV27dtXx48flcrlaMi4AAAAACBheF05vvPGGli5dWqftRz/6kfr06aOrr75aQ4YM0YkTJ1o6PgAAAADwO68Lp+XLlys2NtYzvW7dOr3++ut68803tX37dnXu3FmLFy9ulSABAAAAwJ+8vsfp888/V1pammf6L3/5i771rW/p7rvvliQ999xzuu+++1o+QgAAAADwM6/POFVUVCgmJsYzvXnz5jpfhNunTx8VFBS0bHQAAAAAEAC8Lpx69eqlnTt3SpKKioq0b98+3XjjjZ7XCwoK6lzKBwAAAAAdhdeX6t17772aPXu29u3bp3/84x8aMGCARo4c6Xl98+bNGjJkSKsECQAAAAD+5HXhNG/ePJWXl+vdd99VcnKy3nnnnTqv/+tf/9IPf/jDFg8QAAAAAPzN68LJYrHo6aef1tNPP93o6/ULKQAAAADoKC75C3ABAAAAIFhQOAEAAACACQonAAAAADBB4QQAAAAAJiicAAAAAMCE10/Vq5WRkdFou2EYCg8PV79+/XT77bcrPj7+soMDAAAAgEDgc+G0e/du7dq1SzU1Nbrqqqvkdrv1n//8RyEhIRowYID+8Ic/6L//+7/1ySefaNCgQa0RMwAAAAC0KZ8v1bv99tt1yy23KC8vTzt37tSuXbt06tQpjR8/Xj/84Q916tQpjR07Vo8//nhrxAsAAAAAbc7nwunXv/61nn76acXExHjaYmJitGjRIv3qV79SZGSknnrqKe3cubNFAwUAAAAAf/H5Ur2SkhIVFhY2uAzvyy+/lN1ulyR17txZVVVVLRMhAKBdqXG5tfXIGW05fEZut1udI61KjA5Xcky4rkuNV4jFqNv38BltPlykvHMV6hYXodF9EjWqb0KdfrW25RarqLxaiZ1skiEVnXcoKfrCcmtfLyytVFJ0uEb2itPOY2cbTBeUVKi4rEpxkWE6W16lzpFhOldepfhOYUqOjdDIXnHanlusLUeKJBlK75ugUX0aj6d2HS4et3Ydzdpr44iPsjW6bZoao7F1r79Nt+UWq8BeqaJSh4rLHco/V6mkmDCVO1wyDEM94yM1oGu0iiuqlNjJpuoal97bc0onisvlcNYoMcqqsxXVOl3iUIWzWqWVNXJ9tfxIq6HUxAjlnXPIWeNWp3CrhneP1slzVapxuVRS4VRVtUvh1hD1TQjXyZIqnSmrUlW1S263W/GdwnTjlV10XWqCEjuF6aN9+co59KXsFQ5ZZFGVyyW3S4oMdesXadLQRR/LUWMoRJLzkvZItISYcIsmDUnWzVd21e82HNbJs+XqFBaqUX07q8opnSqpUFW1W8kx4bq+T4KmjeqlPSfOXdhno2xyudz6NLdYklvpzRzjjWnqWALams+F0+23366ZM2fqN7/5ja699loZhqFt27Zpzpw5uuOOOyRJ27ZtU//+/U2XtWzZMi1btkxHjx6VJA0ePFhPPfWUbr311ibn2bBhgzIyMrRv3z5169ZNc+fO1axZs3xdDQBAK1j3Wb6eeHevzpU3/hE3JTZcC6cM0qQhKU32/f0/D6tzpFXP33m1Jg1JkST97cBpSdLMN7bLUdPwA1PnSKsk1VmWxZBcbjU53RRD0sXdXv7nFw3iuXh9F3+wX/kllXXW8VvXpGjtv/O9ar/49dptYzZGU/OZ9W0J5U639uWXe6bPVzm0br+jkZ5OnTzXMI5TJQ79acdJ/WnHyUbmcXn+V+n6usVV5xX4g73SpT/vyNOfd+R52s5VVCtzV0Gdfp/l2fW3g4V6NutAk8t6uZFjvClNHWONHStAa/P5Ur1XXnlFN998s37wgx+oV69e6tmzp37wgx/o5ptv1vLlyyVJAwYM0B//+EfTZXXv3l3PP/+8duzYoR07duib3/ymbr/9du3bt6/R/rm5uZo8ebLGjBmj3bt3a8GCBXr00UeVmZnp62oAAFrYus/yNWv1riaLJknKL6nUQ6t3aUnW/mb7nit3atbqXVr3Wb7WfZavx/+0p9mxz5U7GyyrfpHkTdEk1S2aGoun1rrP8vXQ6l0NipT8kkq9sjHX6/aLX3/IyzEuVnDRNjXrCwSKxo6p+pra/wsaOVaAtuDzGaeoqCitWLFCv/3tb3XkyBG53W717dtXUVFRnj7Dhg3zallTpkypM/3ss89q2bJl2rp1qwYPHtyg//Lly9WzZ08tXbpUkjRw4EDt2LFDL7zwgu666y5fVwUA0EJqXG4tWrvf6/6vbsz1qt+itRf+kOZlzdPqFn+wX+MHJXv+3xpx+TpG7esrNuUGzHYCvLVo7T6NH5Tc4NK7Gpe7yf3frQtnhmuPFS7bQ1vxuXCqFRUVpaFDh7ZYIDU1NXrnnXdUVlam9PT0Rvts2bJFEyZMqNM2ceJErVy5Uk6nU1artcE8DodDDsfXlxDU3ofldDrldHK1dEdQm0fyGTzIeeDZlluss2UVsoW07HLPll34S7PN4q7zr78Un6/Q1i8KPf9v6fVtqzHag0DJOVrX2bJKbf2iUNelxtd5b9+dW2y6/9ceK7X3OKL9CYTf576Mbbjdbp/ekcrKyvT888/r73//uwoLC+Vy1b3q+MiRI74sTnv37lV6eroqKysVFRWlNWvWaPLkyY327d+/v2bMmKEFCxZ42jZv3qwbbrhBeXl5SklpeK3rokWLtHjx4gbta9asUWRkpE+xAgAAAOg4ysvLNXXqVJWUlNR5anhjfD7j9MADD2jDhg265557lJKSIsO4vNOjV111lfbs2aNz584pMzNT06dP14YNG5r88tz649XWfU3FMX/+fGVkZHim7Xa7evTooQkTJphuHLQPTqdT2dnZGj9+fKNnHdHxkPPAsy23WDPf2N5qy7dZ3Ho6zaWf77DI4fLvZTmvTb9Wklp1fdtijEAXSDlH63pt+rWeM0617+27T5Z6tf/Xzov2KRB+n9dejeYNnwunjz76SB9++KFuuOEGX2dtVFhYmPr16ydJSktL0/bt2/Xiiy/qlVdeadA3OTlZBQV1n95SWFio0NBQJSQkNLp8m80mm83WoN1qtfKBq4Mhp8GHnAeOUf2SFNcpQgV28wcT1H4E9uZyh+SYC+/f5766ZM/hMhp9ql5bSYkN16h+SZKk+KgIFZRUtuh9RYak5Escw2JIbnfg3A/WUvydc7Su5BibRvVLqnOfktVq1ah+Sc3u/xcfK9zj1P758/e5L+P6/FS9uLg4xce3XmXvdrvr3JN0sfT0dGVnZ9dpW79+vdLS0vjwBAB+FGIxtOhbjV8p0JgfjU31qt+ibw3Wom81fFiQvyycMkghFkMhFkMLp1xY35b+yObrGMZXPw+O8W6bAoFk0bcGN1r4NLf/107XHitAW/G5cHr66af11FNPqby83LyziQULFmjTpk06evSo9u7dqyeffFI5OTm6++67JV24zO7ee+/19J81a5aOHTumjIwMHThwQK+99ppWrlypOXPmXHYsAIDLM2lIipZPG+H5TqXGpMSGa9m0EZo/eVCzfTtHWrV82ghNGpKiSUNS9NvvD2t27M6R1gbLqv95ytvPV411i7sonlqThqRo2bQRSo4Nr9M3JTZcPx6bqhQv2y9+fZmXY1ws+aJtumzaiCaXDwSSzo0cU/U1tf8nN3KsAG3B50v1fvOb3+jw4cPq2rWrevfu3eBMz65du7xe1unTp3XPPfcoPz9fsbGxGjp0qNatW6fx48dLkvLz83X8+HFP/9TUVGVlZenxxx/X73//e3Xr1k0vvfQSjyIHgAAxaUiKxg9K1tYjZ7Tl8Bm53W51jrQqMTpcyTHhui413vMXYk/fw2e0+XCR8s5VqFtchEb3SdSovgl1/pJ8y8Cuysq9cD9DUXm1EjvZJEMqOu9QUnS45x6HbbnFKiytVFJ0uEb2itPOY2cbTBeUVKi4rEpxkWE6W16lzpFhOldepfhOYUqOjdDIXnHanlusLUeKJBlK75ugUX0SGv3Ldu06XDxu7TrOnTSw2fbaOOKjbA22TXNjNLbu9bfpttxiFdgrVVTqUHG5Q/nnKpUUE6Zyh0uGYahnfKQGdI1WcUWVEjvZVF3j0nt7TulEcbkczholRll1tqJap0scqnBWq7SyxvMFtJFWQ6mJEco755Czxq1O4VYN7x6tk+eqVONyqaTCqapql8KtIeqbEK6TJVU6U1alqmqX3G634juF6cYru+i61AQldgrTR/vylXPoS9krHLLIoiqXS26XFP7Vn3YtX/2ESOI5mv4TE27RpCHJuvnKrvrdhsM6ebZcncJCNapvZ1U5pVMlFaqqdis5JlzX90nQtFG9tOfEuQv7bJRNLpdbn+YWS3IrvZFjvCnNHWNAW/P5qXqNPaHuYgsXLrysgFqb3W5XbGysV0/OQPvgdDqVlZWlyZMnc8lmkCDnwYecBx9yHnzIefAJhJz7Uhv4fMYp0AsjAAAAAGhpPt/jBAAAAADBxqszTvHx8fr888+VmJiouLi4Zr+7qbi4uMWCAwAAAIBA4FXh9Nvf/lbR0dGe/1/ul94CAAAAQHviVeE0ffp0z/9nzJjRWrEAAAAAQEDy+R6nkJAQFRYWNmg/c+aMQkJCWiQoAAAAAAgkPhdOTT293OFwKCws7LIDAgAAAIBA4/XjyF966SVJkmEY+uMf/6ioqCjPazU1Ndq4caMGDBjQ8hECAAAAgJ95XTj99re/lXThjNPy5cvrXJYXFham3r17a/ny5S0fIQAAAAD4mdeFU25uriRp3LhxevfddxUXF9dqQQEAAABAIPH5Hqd//vOfdYqmmpoa7dmzR2fPnm3RwAAAAAAgUPhcOD322GNauXKlpAtF09ixYzVixAj16NFDOTk5LR0fAAAAAPidz4XTO++8o2uuuUaS9MEHH+jo0aM6ePCgHnvsMT355JMtHiAAAAAA+JvPhdOZM2eUnJwsScrKytJ3v/td9e/fX/fff7/27t3b4gECAAAAgL/5XDh17dpV+/fvV01NjdatW6dbbrlFklReXs4X4AIAAADokLx+ql6t++67T9/73veUkpIiwzA0fvx4SdKnn37K9zgBAAAA6JB8LpwWLVqkIUOG6MSJE/rud78rm80mSQoJCdETTzzR4gECAAAAgL/5XDhJ0ne+8x1JUmVlpadt+vTpLRMRAAAAAAQYn+9xqqmp0dNPP60rrrhCUVFROnLkiCTp5z//uecx5QAAAADQkfhcOD377LNatWqVfvWrXyksLMzTfvXVV+uPf/xjiwYHAAAAAIHA58LpzTff1Kuvvqq77767zlP0hg4dqoMHD7ZocAAAAAAQCHwunE6dOqV+/fo1aHe5XHI6nS0SFAAAAAAEEp8Lp8GDB2vTpk0N2t955x0NHz68RYICAAAAgEDi9VP1Zs6cqRdffFELFy7UPffco1OnTsnlcundd9/VoUOH9Oabb+qvf/1ra8YKAAAAAH7h9RmnN954QxUVFZoyZYr+9Kc/KSsrS4Zh6KmnntKBAwf0wQcfeL4MFwAAAAA6Eq/POLndbs//J06cqIkTJ7ZKQAAAAAAQaHy6x8kwjNaKAwAAAAACltdnnCSpf//+psVTcXHxZQUEAAAAAIHGp8Jp8eLFio2Nba1YAAAAACAg+VQ4/eAHP1BSUlJrxQIAAAAAAcnre5y4vwkAAABAsPK6cLr4qXoAAAAAEEy8vlTP5XK1ZhwAAAAAELB8ehx5S1uyZImuvfZaRUdHKykpSXfccYcOHTrU7Dw5OTkyDKPBz8GDB9soagAAAADBxq+F04YNGzR79mxt3bpV2dnZqq6u1oQJE1RWVmY676FDh5Sfn+/5ufLKK9sgYgAAAADByKen6rW0devW1Zl+/fXXlZSUpJ07d2rs2LHNzpuUlKTOnTu3YnQAAAAAcIFfC6f6SkpKJEnx8fGmfYcPH67KykoNGjRIP/vZzzRu3LhG+zkcDjkcDs+03W6XJDmdTjmdzhaIGv5Wm0fyGTzIefAh58GHnAcfch58AiHnvoxtuAPkcXlut1u33367zp49q02bNjXZ79ChQ9q4caNGjhwph8Oht956S8uXL1dOTk6jZ6kWLVqkxYsXN2hfs2aNIiMjW3QdAAAAALQf5eXlmjp1qkpKShQTE9Ns34ApnGbPnq0PP/xQn3zyibp37+7TvFOmTJFhGFq7dm2D1xo749SjRw8VFRWZbhy0D06nU9nZ2Ro/frysVqu/w0EbIOfBh5wHH3IefMh58AmEnNvtdiUmJnpVOAXEpXqPPPKI1q5dq40bN/pcNEnSqFGjtHr16kZfs9lsstlsDdqtVisHZQdDToMPOQ8+5Dz4kPPgQ86Djz9z7su4fi2c3G63HnnkEb333nvKyclRamrqJS1n9+7dSklJaeHoAAAAAOACvxZOs2fP1po1a/SXv/xF0dHRKigokCTFxsYqIiJCkjR//nydOnVKb775piRp6dKl6t27twYPHqyqqiqtXr1amZmZyszM9Nt6AAAAAOjY/Fo4LVu2TJJ000031Wl//fXXNWPGDElSfn6+jh8/7nmtqqpKc+bM0alTpxQREaHBgwfrww8/1OTJk9sqbAAAAABBxu+X6plZtWpVnem5c+dq7ty5rRQRAAAAADRk8XcAAAAAABDoKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABggsIJAAAAAExQOAEAAACACQonAAAAADBB4QQAAAAAJiicAAAAAMAEhRMAAAAAmKBwAgAAAAATFE4AAAAAYILCCQAAAABMUDgBAAAAgAkKJwAAAAAwQeEEAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGCCwgkAAAAATFA4AQAAAIAJCicAAAAAMEHhBAAAAAAmKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABggsIJAAAAAExQOAEAAACACQonAAAAADAR6u8AglmNy61tucUqLK1UUnS4rkuNV4jF8HdY7SKuxCib5JaKyhxKjPRtN66qdumNzUe1/WixIq0hGtgtWkkxEUqOaXpd62+Tkb3itPPYWZ+3kbfb1qxfW+YoUPeHi7WHGNG+XM4+VeNya+vhM9pypEiSofS+CRrVJ+GSjvVmxzhyRlsOn5Hk1vW9E2QJMVR03qGk6HAN69FZaz49psNF5/Wl3aGuMeFKTeykqdf30o7cYmXuPqnyqhoN6xGrk2crdOJshXonRGrepIH698lz2vxFkU6eLZfb7VaNy619eXadd1TLkEuhFotq3NJ5h1OVTsmlC3+FtYVIMqTKailEUpjVoqgwi9wyVFZVrQqnW+4LXWTownzNsYW49avrpCGLPpajhuM5GLSXnBuS3PXabBYpIcqmcKtFZ8qqVO6okSyGune2KcQSIsktwzDUo3O4IsNClFfi0HlHjTrZQhQWYui03SFJiu8UpnBriBKjbHLLrTOlDlXWuBQeGqIu0eG6onOEYsJDdaDArnJnjbpE2RQbYVWIxeLVe03euQrtOXFWktQ7oZPuSe+tsFDOo3jLr4XTkiVL9O677+rgwYOKiIjQ6NGj9ctf/lJXXXVVs/Nt2LBBGRkZ2rdvn7p166a5c+dq1qxZbRR1y1j3Wb4Wf7Bf+SWVnraU2HAtnDJIk4akEJcXcdWqfaP924HTunVo92aXsyRrv17dlCv3Re947//76/83tq6NjW0xJJe7+fm8WQdvx7u4X1vmKFD3h4u1hxjRvlzOPrXus3w98e5enSt3etpe/ucX6hxp1fN3Xu3Tse7TGDrs1bo9/eGBOtPr95/2/H/Tf6S3th73Yik1DVpckiouaq6WVO10qdzZsDxyq+GHTqA9aWz/dbikvK+KH48at3LP1P3c8p/CsmaXfbS44pLj8uW9ptazWQf04JhUzZ886JLHDSZ+LTE3bNig2bNna+vWrcrOzlZ1dbUmTJigsrKmd6rc3FxNnjxZY8aM0e7du7VgwQI9+uijyszMbMPIL8+6z/L10OpdDXbggpJKPbR6l9Z9lk9cXsRV3+N/2tNsjEuy9uuVjXWLpvry661rU2O76i3DbBt5u23N+i3J2t9mOQrU/eFifztwOuBjRPtyOfv9us/yNWv1rjoFTa1z5U7N8uFYb+69pKkxAMDb95paLrf0ysZcLcna35Zhtlt+LZzWrVunGTNmaPDgwbrmmmv0+uuv6/jx49q5c2eT8yxfvlw9e/bU0qVLNXDgQD3wwAOaOXOmXnjhhTaM/NLVuNxa/MH+Rv9aUdu2+IP9qqn/ybyVtce4GtNUjFXVLq3YlOv1uIs/2K+qapfXYze3jbzdts2NV/sX2hWbctskR4G6P9T3/EcHAz5GtB+Xs9/XuNxatHaf6RjeHOtNjXNhDD7cADDn6+eYFZtyVVVtdgEtAuoep5KSEklSfHx8k322bNmiCRMm1GmbOHGiVq5cKafTKavVWuc1h8Mhh+PrU6d2u12S5HQ65XS2/V/stuUWq/h8xYVrwZtQfL5CW78o1HWpTW8H4vqazXLhLSHM4m4yxtVbjspq8f4DdPH5Cq3efNh07Mbmqz++t9v2UsbzZvxLEaj7Q63aY/fs+QrZQpq+Dt6fMaJl1ea8Nd+3L2e/35ZbrLNllabHr7fHelPvJWfLLu89oj2pfW+3+fDejfaNnLecS/lcsXrzYd2T3rtV46qvLd7bvY3BG4bb3dyFS23H7Xbr9ttv19mzZ7Vp06Ym+/Xv318zZszQggULPG2bN2/WDTfcoLy8PKWk1L0ufNGiRVq8eHGD5axZs0aRkZEttwIAAAAA2pXy8nJNnTpVJSUliomJabZvwJxxevjhh/V///d/+uSTT0z7GkbdvzDX1n712yVp/vz5ysjI8Ezb7Xb16NFDEyZMMN04rWFbbrFmvrHdtN9r069t8zM77TUum8Wtp9Nc+vkOixwuo9EY39pyVL/8+JBPY8+beJXP80gNt5G32/ZSxzMb/1IE6v5Qy+l0Kjs725Pz5vgrRrSs2pyPHz++wZUFLeVy9ntv55W8P9Yv9b2ko6j/3o6Oj5y3LF8/V8ybeJVfzji19nu7mdqr0bwREIXTI488orVr12rjxo3q3r35p6IlJyeroKCgTlthYaFCQ0OVkJDQoL/NZpPNZmvQbrVa/ZKgUf2SFB8VoYKSykavOTUkJceGa1S/pDZ9nHJ7jetiVS5D8VERjcY4bXRfPfPR5w0e6tCY2nWdNrqvVvzruFdjXzxf/fG93bbejGcxJLe78Sf6tGSOAnV/qC8uKkLHzzoCOka0rNZ8776c/X5UvyTFdQpXQf2natWT4sWx3tx7SVynCBXYm39QTkfjcBkB/WhqtDxyfvkufq8xe7iWdOHzxbTRfWX106PJ/fW5vHZsb/n14RBut1sPP/yw3n33Xf3jH/9Qamqq6Tzp6enKzs6u07Z+/XqlpaX5bYP7IsRiaOGUC498rP+WUDu9cMqgNv+g1x7jakxTMYaFWvTgGPP96+LlhIVavB67uW3k7bZtbrza7z2pXYfWzlGg7g/1PXHrAEmBHSPaj8vZ70MshhZ9a7DpGN4c602Nc2EMHhkMwNzF7zXe/BZ8cEwq3+fkBb9uodmzZ2v16tVas2aNoqOjVVBQoIKCAlVUfP0M+/nz5+vee+/1TM+aNUvHjh1TRkaGDhw4oNdee00rV67UnDlz/LEKl2TSkBQtmzZCybHhddqTY8O1bNoIv333THuLq77ffn9YszHOnzxIPx6bqkau6PRIqbeuTY1d/3OT2Tbydtua9Zs/eVCb5ShQ94eL3TKwa8DHiPblcvb7SUNStHzaCHWObPhHvLhIq5b7cKw3917S1BgA0NR7TUoTn6EshvTjsXyPk7f8+nCIxu5JkqTXX39dM2bMkCTNmDFDR48eVU5Ojuf1DRs26PHHH/d8Ae68efO8/gJcu92u2NhYr24Aa22X8830wR5XYpRNcktFZQ4lRoaq6MBWTZ482auzjlXVLr2x+ai2Hy1WpDVEA7tFKykmQskxTa9r/W0yslecdh476/M28nbbmvVryxwF4v7gdDqVlZXlyXkgxoiWVT/nre1y9qkal1tbD5/RliNFkgyl903QqD4Jl3SsNzvGkTPacviMJLeu750gS4ihovMOJUWHa1iPzlrz6TEdLjqvL+0OdY0JV2piJ029vpd25BYrc/dJlVfVaFiPWJ08W6ETZyvUOyFS8yYN1L9PntPmL4p08my53G63alxu7cuz67yjWoZcCrVYVOOWzjucqnRe+PJbi3ThyV2GVFkthUgKs1oUFWaRW4bKqqpV4XTLra/PoJs9+PjCl5vXaO62EC7bChLtJeeGGl4yb7NICVE2hVstOlNWpXJHjWQx1L2zTSGWEEluGYahHp3DFRkWorwSh847atTJFqKwEEOnv7rMN75TmMKtIUqMssktt86UOlRZ41J4aIi6RIfris4RigkP1YECu8qdNeoSZVNshFUhFotX7zV55yq058RZSVLvhE66J723X880tfV7e2N8qQ0C5ql6bSWQCie0jEA46NC2yHnwIefBh5wHH3IefAIh577UBlzMCAAAAAAmKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABggsIJAAAAAExQOAEAAACACQonAAAAADBB4QQAAAAAJiicAAAAAMAEhRMAAAAAmKBwAgAAAAATFE4AAAAAYILCCQAAAABMUDgBAAAAgAkKJwAAAAAwQeEEAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGCCwgkAAAAATFA4AQAAAIAJCicAAAAAMEHhBAAAAAAmKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABggsIJAAAAAExQOAEAAACACQonAAAAADDh18Jp48aNmjJlirp16ybDMPT+++832z8nJ0eGYTT4OXjwYNsEDAAAACAohfpz8LKyMl1zzTW67777dNddd3k936FDhxQTE+OZ7tKlS2uEBwAAAACS/Fw43Xrrrbr11lt9ni8pKUmdO3du+YAAAAAAoBF+LZwu1fDhw1VZWalBgwbpZz/7mcaNG9dkX4fDIYfD4Zm22+2SJKfTKafT2eqxovXV5pF8Bg9yHnzIefAh58GHnAefQMi5L2Mbbrfb3YqxeM0wDL333nu64447muxz6NAhbdy4USNHjpTD4dBbb72l5cuXKycnR2PHjm10nkWLFmnx4sUN2tesWaPIyMiWCh8AAABAO1NeXq6pU6eqpKSkzq1AjWlXhVNjpkyZIsMwtHbt2kZfb+yMU48ePVRUVGS6cdA+OJ1OZWdna/z48bJarf4OB22AnAcfch58yHnwIefBJxBybrfblZiY6FXh1C4v1bvYqFGjtHr16iZft9lsstlsDdqtVisHZQdDToMPOQ8+5Dz4kPPgQ86Djz9z7su47f57nHbv3q2UlBR/hwEAAACgA/PrGafz58/riy++8Ezn5uZqz549io+PV8+ePTV//nydOnVKb775piRp6dKl6t27twYPHqyqqiqtXr1amZmZyszM9NcqAAAAAAgCfi2cduzYUeeJeBkZGZKk6dOna9WqVcrPz9fx48c9r1dVVWnOnDk6deqUIiIiNHjwYH344YeaPHlym8cOAAAAIHj4tXC66aab1NyzKVatWlVneu7cuZo7d24rRwUAAAAAdbX7e5wAAAAAoLVROAEAAACACQonAAAAADBB4QQAAAAAJiicAAAAAMAEhRMAAAAAmKBwAgAAAAATFE4AAAAAYILCCQAAAABMUDgBAAAAgAkKJwAAAAAwQeEEAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGCCwgkAAAAATFA4AQAAAIAJCicAAAAAMEHhBAAAAAAmKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABggsIJAAAAAExQOAEAAACACQonAAAAADBB4QQAAAAAJiicAAAAAMAEhRMAAAAAmKBwAgAAAAATFE4AAAAAYCLU3wEAQHtT43JrW26xCksrlRQdrutS4yWpTtvIXnHaeexsnT4hFqNFx2xqeb709XY+s9e2HjmjLYfPSHIrvU+iRvVNuKz1bU9qXG5tPXxGW44UyeWWYiOsOlfuVEFJhbrFRWhU7wRZQgwVnXfU2TdOFpdp/f7TqnC61DshQuMHJqu4wqmiUofOlFWqoMShK+IiNLpvokb0jNPqrce0LbdI5VUuJUTZdEVsuDp3supchVN5ZyskGZJbchtuGW63DItFV3SO0Oh+iRrVxzwfTe3XF+f2+t4JkiFtOXJGJ4rLtP/EGR0+62yV7WoLcetX10lDFn0sR01w7EtmesaG6v1Hxik+KszTVpu3Anulis87FN8pTMmxEXXelwpKKlRcVqX4KJuSYy7K7Vf7rWTo2l5x+rzwvI6eKVOhvVJJMTb1SYzSPem9FRba9N/Zg/34R3Dxa+G0ceNG/frXv9bOnTuVn5+v9957T3fccUez82zYsEEZGRnat2+funXrprlz52rWrFltEzCAoLfus3wt/mC/8ksqPW2dI62SpHPlX3+AtBiSy/31fCmx4Vo4ZZAmDUlpkTGbWp4vfb2dT1Kzrz3x7t466/7yPw+rc6RVz9959SWtb3uy7rP8Butf3+91uM50/X1Dkj75Qlr96YnG5//n4UbbvfX7HPN8NLVfV1W7VF5V42l7WZcXCy7P8ZJqjXgmW12iwrT9Z+MbzVutxt6XLn6tfm6b8mzWAT04JlXzJw9q8Fpj+38wHf8IPn69VK+srEzXXHONXn75Za/65+bmavLkyRozZox2796tBQsW6NFHH1VmZmYrRwoAFz4kPLR6V4MPKefKnQ0+nNT/YFxQUqmHVu/Sus/yW2TMxpbnS19vx5i1epdmmbzW2Aezc+VOzbqE9W1P1n2W3+T6N6f+vtEWmstHc/u1Nx+s0fa+PF+loYs+bjRvtRp7X7r4NW9z63JLr2zM1ZKs/XXam9v/g+H4R3Dya+F066236plnntGdd97pVf/ly5erZ8+eWrp0qQYOHKgHHnhAM2fO1AsvvNDKkQIIdjUutxZ/sF+X+pm3dr7FH+xXjZefnJsbs/7yfOnr6xiN8XY7LFq7z+v1bU9qXG4tWrvP32H4rP4+cLn7NfzHXlndpnlbsSlXVdUuSbX7/36TOTru8Y/g1a7ucdqyZYsmTJhQp23ixIlauXKlnE6nrFZrg3kcDoccDodn2m63S5KcTqeczta5LhttqzaP5DN4+CPn23KLVXy+QraQy1tO8fkKbf2i0HOPweWOWbu82v970/fisVtqvZpytqzS6/VtTqAd59tyi3W2rLLVtltrqb8PtHb+L4fN4q7zL/xv9ebDuie991f7v/l+4+vxH2jHOVpfIOTcl7ENt9sdEO9IhmGY3uPUv39/zZgxQwsWLPC0bd68WTfccIPy8vKUktLwWtpFixZp8eLFDdrXrFmjyMjIFokdAAAAQPtTXl6uqVOnqqSkRDExMc32bVdnnKQLBdbFauu++u215s+fr4yMDM+03W5Xjx49NGHCBNONg/bB6XQqOztb48ePb/SsIzoef+R8W26xZr6xvUWW9dr0a70+4+TNmK9Nv1aSvO5b/4xTS62Xt2NeikA7zttiu7WWi/MRyOths7j1dJpLP99hkcPFE9oCwbyJV3nOOHm73/hy/AfacY7WFwg5r70azRvtqnBKTk5WQUFBnbbCwkKFhoYqISGh0XlsNptsNluDdqvVykHZwZDT4NOWOR/VL0nxUREqKKm85PsKDEnJseEa1S/Jq0f1mo158fIked334rFbYr2akxxj83p9vREox/mofkmK6xSuArvDvHMASam3D7R2/luCw2XwOPIAYDGkaaP7yhpq+Wr/j1CBvfEHU9S61OM/UI5ztB1/5tyXcdvVF+Cmp6crOzu7Ttv69euVlpbGAQagVYVYDM/jty/lI1ztPAunDPL6Q0RzY9Zfni99fR3D7LXmLPrW4A75fS4hFkOLvjXY32H4rP4+cLn7NfwnJjy0TXP24JhUz/c5Xdj/Gz6evL6OevwjePm1cDp//rz27NmjPXv2SLrwuPE9e/bo+PHjki5cZnfvvfd6+s+aNUvHjh1TRkaGDhw4oNdee00rV67UnDlz/BE+gCAzaUiKlk0boeTY8DrtnSOtnu9MqVX/s0JybLiWTRvh8/eaNDVmY8vzpa+3YyyfNkLLTV6rv+7ShW2y/BLWtz2ZNCSlyfVvjj8+R8Y1k4+m8h8XaVVkWAA+NQLqEhWm/1s0UcumjVBKvbzVimvkfalWZx9yazGkH49t+D1Oze3/wXD8Izj59VK9HTt2aNy4cZ7p2nuRpk+frlWrVik/P99TRElSamqqsrKy9Pjjj+v3v/+9unXrppdeekl33XVXm8cOIDhNGpKi8YOStS23WIWllUqKDq9zv0ht28hecdp57GydPpf6l9emxmxseb709WU+s9e2HjmjLYfPSHIrvU+iRvVNCIq/NNdut62Hz2jLkSK53FJshFXnyp0qKKlQt7gIjeqdIEuIoaLzjjr7xsniMq3ff1oVTpd6J0Ro/MBkFVc4VVTq0JmyShWUOHRFXIRG903UiJ5xWr31mLblFqm8yqWEKJuuiA1X505WnatwKu9shSRDcktuwy3D7ZZhseiKzhEa3S9Ro/o0n4/m9uuLc3t97wTJkLYcOaMTxWXaf+KMDp/lCWhtpWdsqN5/ZJzio8Ik1c1bgb1Sxecdiu8UpuTYiDrvSwUlFSouq1J8lE3JMRfl9qv9VjJ0ba84fV54XkfPlKnQXqmkGJv6JEbpnvTenjNN9Xn2/yA9/hF8Auapem3FbrcrNjbWqydnoH1wOp3KysrS5MmTuWQzSJDz4EPOgw85Dz7kPPgEQs59qQ3a1T1OAAAAAOAPFE4AAAAAYILCCQAAAABMUDgBAAAAgAkKJwAAAAAwQeEEAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGAi1N8BtDW32y1Jstvtfo4ELcXpdKq8vFx2u11Wq9Xf4aANkPPgQ86DDzkPPuQ8+ARCzmtrgtoaoTlBVziVlpZKknr06OHnSAAAAAAEgtLSUsXGxjbbx3B7U151IC6XS3l5eYqOjpZhGP4OBy3AbrerR48eOnHihGJiYvwdDtoAOQ8+5Dz4kPPgQ86DTyDk3O12q7S0VN26dZPF0vxdTEF3xslisah79+7+DgOtICYmhjfaIEPOgw85Dz7kPPiQ8+Dj75ybnWmqxcMhAAAAAMAEhRMAAAAAmKBwQrtns9m0cOFC2Ww2f4eCNkLOgw85Dz7kPPiQ8+DT3nIedA+HAAAAAABfccYJAAAAAExQOAEAAACACQonAAAAADBB4QQAAAAAJiic0CE5HA4NGzZMhmFoz549/g4HreTo0aO6//77lZqaqoiICPXt21cLFy5UVVWVv0NDC/vDH/6g1NRUhYeHa+TIkdq0aZO/Q0IrWbJkia699lpFR0crKSlJd9xxhw4dOuTvsNBGlixZIsMw9Nhjj/k7FLSyU6dOadq0aUpISFBkZKSGDRumnTt3+jusZlE4oUOaO3euunXr5u8w0MoOHjwol8ulV155Rfv27dNvf/tbLV++XAsWLPB3aGhBf/rTn/TYY4/pySef1O7duzVmzBjdeuutOn78uL9DQyvYsGGDZs+era1btyo7O1vV1dWaMGGCysrK/B0aWtn27dv16quvaujQof4OBa3s7NmzuuGGG2S1WvXRRx9p//79+s1vfqPOnTv7O7Rm8ThydDgfffSRMjIylJmZqcGDB2v37t0aNmyYv8NCG/n1r3+tZcuW6ciRI/4OBS3k+uuv14gRI7Rs2TJP28CBA3XHHXdoyZIlfowMbeHLL79UUlKSNmzYoLFjx/o7HLSS8+fPa8SIEfrDH/6gZ555RsOGDdPSpUv9HRZayRNPPKF//etf7e7qAc44oUM5ffq0HnzwQb311luKjIz0dzjwg5KSEsXHx/s7DLSQqqoq7dy5UxMmTKjTPmHCBG3evNlPUaEtlZSUSBLHdQc3e/Zs3Xbbbbrlllv8HQrawNq1a5WWlqbvfve7SkpK0vDhw7VixQp/h2WKwgkdhtvt1owZMzRr1iylpaX5Oxz4weHDh/W73/1Os2bN8ncoaCFFRUWqqalR165d67R37dpVBQUFfooKbcXtdisjI0M33nijhgwZ4u9w0Erefvtt7dq1izPIQeTIkSNatmyZrrzySn388ceaNWuWHn30Ub355pv+Dq1ZFE4IeIsWLZJhGM3+7NixQ7/73e9kt9s1f/58f4eMy+Rtzi+Wl5enSZMm6bvf/a4eeOABP0WO1mIYRp1pt9vdoA0dz8MPP6z/+7//0//+7//6OxS0khMnTugnP/mJVq9erfDwcH+Hgzbicrk0YsQIPffccxo+fLh+/OMf68EHH6xzSXYgCvV3AICZhx9+WD/4wQ+a7dO7d28988wz2rp1q2w2W53X0tLSdPfdd+uNN95ozTDRgrzNea28vDyNGzdO6enpevXVV1s5OrSlxMREhYSENDi7VFhY2OAsFDqWRx55RGvXrtXGjRvVvXt3f4eDVrJz504VFhZq5MiRnraamhpt3LhRL7/8shwOh0JCQvwYIVpDSkqKBg0aVKdt4MCByszM9FNE3qFwQsBLTExUYmKiab+XXnpJzzzzjGc6Ly9PEydO1J/+9Cddf/31rRkiWpi3OZcuPM503LhxGjlypF5//XVZLJxI70jCwsI0cuRIZWdn69vf/ranPTs7W7fffrsfI0NrcbvdeuSRR/Tee+8pJydHqamp/g4Jrejmm2/W3r1767Tdd999GjBggObNm0fR1EHdcMMNDb5m4PPPP1evXr38FJF3KJzQYfTs2bPOdFRUlCSpb9++/LWyg8rLy9NNN92knj176oUXXtCXX37peS05OdmPkaElZWRk6J577lFaWprnrOLx48e5l62Dmj17ttasWaO//OUvio6O9pxtjI2NVUREhJ+jQ0uLjo5ucP9ap06dlJCQwH1tHdjjjz+u0aNH67nnntP3vvc9bdu2Ta+++mrAXzVC4QSg3Vq/fr2++OILffHFFw2KY75poeP4/ve/rzNnzugXv/iF8vPzNWTIEGVlZQX8XyZxaWrvcbjpppvqtL/++uuaMWNG2wcEoMVde+21eu+99zR//nz94he/UGpqqpYuXaq7777b36E1i+9xAgAAAAAT3AwAAAAAACYonAAAAADABIUTAAAAAJigcAIAAAAAExROAAAAAGCCwgkAAAAATFA4AQAAAIAJCicAQIeyaNEiDRs2zDM9Y8YM3XHHHZe1zJZYBgCgfaNwAgC0iRkzZsgwDBmGIavVqj59+mjOnDkqKytr1XFffPFFrVq1yqu+R48elWEY2rNnzyUvAwDQMYX6OwAAQPCYNGmSXn/9dTmdTm3atEkPPPCAysrKtGzZsjr9nE6nrFZri4wZGxsbEMsAALRvnHECALQZm82m5ORk9ejRQ1OnTtXdd9+t999/33N53WuvvaY+ffrIZrPJ7XarpKREP/rRj5SUlKSYmBh985vf1L///e86y3z++efVtWtXRUdH6/7771dlZWWd1+tfZudyufTLX/5S/fr1k81mU8+ePfXss89KklJTUyVJw4cPl2EYuummmxpdhsPh0KOPPqqkpCSFh4frxhtv1Pbt2z2v5+TkyDAM/f3vf1daWpoiIyM1evRoHTp0yNPn3//+t8aNG6fo6GjFxMRo5MiR2rFjR0tsZgBAK6BwAgD4TUREhJxOpyTpiy++0J///GdlZmZ6LpW77bbbVFBQoKysLO3cuVMjRozQzTffrOLiYknSn//8Zy1cuFDPPvusduzYoZSUFP3hD39odsz58+frl7/8pX7+859r//79WrNmjbp27SpJ2rZtmyTpb3/7m/Lz8/Xuu+82uoy5c+cqMzNTb7zxhnbt2qV+/fpp4sSJnrhqPfnkk/rNb36jHTt2KDQ0VDNnzvS8dvfdd6t79+7avn27du7cqSeeeKLFzrIBAFoel+oBAPxi27ZtWrNmjW6++WZJUlVVld566y116dJFkvSPf/xDe/fuVWFhoWw2myTphRde0Pvvv6//9//+n370ox9p6dKlmjlzph544AFJ0jPPPKO//e1vDc461SotLdWLL76ol19+WdOnT5ck9e3bVzfeeKMkecZOSEhQcnJyo8uovbRw1apVuvXWWyVJK1asUHZ2tlauXKmf/vSnnr7PPvusvvGNb0iSnnjiCd12222qrKxUeHi4jh8/rp/+9KcaMGCAJOnKK6+8xC0JAGgLnHECALSZv/71r4qKilJ4eLjS09M1duxY/e53v5Mk9erVy1O4SNLOnTt1/vx5JSQkKCoqyvOTm5urw4cPS5IOHDig9PT0OmPUn77YgQMH5HA4PMXapTh8+LCcTqduuOEGT5vVatV1112nAwcO1Ok7dOhQz/9TUlIkSYWFhZKkjIwMPfDAA7rlllv0/PPPe9YJABCYOOMEAGgz48aN07Jly2S1WtWtW7c6l6Z16tSpTl+Xy6WUlBTl5OQ0WE7nzp0vafyIiIhLmu9ibrdbkmQYRoP2+m0Xr1/tay6XS9KFx6ZPnTpVH374oT766CMtXLhQb7/9tr797W9fdowAgJbHGScAQJvp1KmT+vXrp169epnezzNixAgVFBQoNDRU/fr1q/OTmJgoSRo4cKC2bt1aZ7760xe78sorFRERob///e+Nvh4WFiZJqqmpaXIZ/fr1U1hYmD755BNPm9Pp1I4dOzRw4MBm16m+/v376/HHH9f69et155136vXXX/dpfgBA2+GMEwAgIN1yyy1KT0/XHXfcoV/+8pe66qqrlJeXp6ysLN1xxx1KS0vTT37yE02fPl1paWm68cYb9T//8z/at2+f+vTp0+gyw8PDNW/ePM2dO1dhYWG64YYb9OWXX2rfvn26//77lZSUpIiICK1bt07du3dXeHh4g0eRd+rUSQ899JB++tOfKj4+Xj179tSvfvUrlZeX6/777/dq3SoqKvTTn/5U3/nOd5SamqqTJ09q+/btuuuuuy57uwEAWgeFEwAgIBmGoaysLD355JOaOXOmvvzySyUnJ2vs2LGep+B9//vf1+HDhzVv3jxVVlbqrrvu0kMPPaSPP/64yeX+/Oc/V2hoqJ566inl5eUpJSVFs2bNkiSFhobqpZde0i9+8Qs99dRTGjNmTKOXCj7//PNyuVy65557VFpaqrS0NH388ceKi4vzat1CQkJ05swZ3XvvvTp9+rQSExN15513avHixb5vKABAmzDctRdrAwAAAAAaxT1OAAAAAGCCwgkAAAAATFA4AQAAAIAJCicAAAAAMEHhBAAAAAAmKJwAAAAAwASFEwAAAACYoHACAAAAABMUTgAAAABggsIJAAAAAExQOAEAAACACQonAAAAADDx/wMT/VUfpVBA4QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Results\n",
    "preds=reg.predict(Xt_test)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(preds, y_test)\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Testing Set')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a18cd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Class</td>      <th>  R-squared:         </th> <td>   0.272</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.271</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   704.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 19 Nov 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:57:53</td>     <th>  Log-Likelihood:    </th> <td> -94420.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 58571</td>      <th>  AIC:               </th> <td>1.889e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 58539</td>      <th>  BIC:               </th> <td>1.892e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    31</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.9837</td> <td>    0.005</td> <td>  595.114</td> <td> 0.000</td> <td>    2.974</td> <td>    2.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0192</td> <td>    0.005</td> <td>    3.595</td> <td> 0.000</td> <td>    0.009</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1791</td> <td>    0.006</td> <td>   32.186</td> <td> 0.000</td> <td>    0.168</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1491</td> <td>    0.006</td> <td>   24.069</td> <td> 0.000</td> <td>    0.137</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0756</td> <td>    0.007</td> <td>   10.195</td> <td> 0.000</td> <td>    0.061</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0964</td> <td>    0.006</td> <td>   17.130</td> <td> 0.000</td> <td>    0.085</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.1863</td> <td>    0.006</td> <td>   29.529</td> <td> 0.000</td> <td>    0.174</td> <td>    0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0551</td> <td>    0.008</td> <td>    7.020</td> <td> 0.000</td> <td>    0.040</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0528</td> <td>    0.006</td> <td>    9.275</td> <td> 0.000</td> <td>    0.042</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2046</td> <td>    0.006</td> <td>   31.675</td> <td> 0.000</td> <td>    0.192</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0198</td> <td>    0.008</td> <td>    2.455</td> <td> 0.014</td> <td>    0.004</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0521</td> <td>    0.006</td> <td>    9.042</td> <td> 0.000</td> <td>    0.041</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.2208</td> <td>    0.007</td> <td>   33.180</td> <td> 0.000</td> <td>    0.208</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0309</td> <td>    0.008</td> <td>   -3.759</td> <td> 0.000</td> <td>   -0.047</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0518</td> <td>    0.006</td> <td>    9.021</td> <td> 0.000</td> <td>    0.041</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.2336</td> <td>    0.007</td> <td>   34.640</td> <td> 0.000</td> <td>    0.220</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0826</td> <td>    0.008</td> <td>  -10.284</td> <td> 0.000</td> <td>   -0.098</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0032</td> <td>    0.006</td> <td>    0.567</td> <td> 0.571</td> <td>   -0.008</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.2296</td> <td>    0.007</td> <td>   33.537</td> <td> 0.000</td> <td>    0.216</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.1758</td> <td>    0.008</td> <td>  -23.129</td> <td> 0.000</td> <td>   -0.191</td> <td>   -0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.0481</td> <td>    0.006</td> <td>   -8.620</td> <td> 0.000</td> <td>   -0.059</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2365</td> <td>    0.007</td> <td>   34.988</td> <td> 0.000</td> <td>    0.223</td> <td>    0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.2995</td> <td>    0.007</td> <td>  -41.807</td> <td> 0.000</td> <td>   -0.314</td> <td>   -0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.1055</td> <td>    0.006</td> <td>  -18.720</td> <td> 0.000</td> <td>   -0.117</td> <td>   -0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1825</td> <td>    0.006</td> <td>   29.593</td> <td> 0.000</td> <td>    0.170</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.2728</td> <td>    0.006</td> <td>  -42.712</td> <td> 0.000</td> <td>   -0.285</td> <td>   -0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.0588</td> <td>    0.006</td> <td>  -10.108</td> <td> 0.000</td> <td>   -0.070</td> <td>   -0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.2347</td> <td>    0.007</td> <td>   36.059</td> <td> 0.000</td> <td>    0.222</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.1805</td> <td>    0.007</td> <td>  -27.321</td> <td> 0.000</td> <td>   -0.193</td> <td>   -0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -0.0078</td> <td>    0.006</td> <td>   -1.310</td> <td> 0.190</td> <td>   -0.020</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.2556</td> <td>    0.007</td> <td>   38.586</td> <td> 0.000</td> <td>    0.243</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.1249</td> <td>    0.006</td> <td>  -19.875</td> <td> 0.000</td> <td>   -0.137</td> <td>   -0.113</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1492.045</td> <th>  Durbin-Watson:     </th> <td>   2.001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 779.935</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.072</td>  <th>  Prob(JB):          </th> <td>4.36e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.454</td>  <th>  Cond. No.          </th> <td>    4.14</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Class       & \\textbf{  R-squared:         } &     0.272   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.271   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     704.6   \\\\\n",
       "\\textbf{Date:}             & Sun, 19 Nov 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     11:57:53     & \\textbf{  Log-Likelihood:    } &   -94420.   \\\\\n",
       "\\textbf{No. Observations:} &       58571      & \\textbf{  AIC:               } & 1.889e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &       58539      & \\textbf{  BIC:               } & 1.892e+05   \\\\\n",
       "\\textbf{Df Model:}         &          31      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       2.9837  &        0.005     &   595.114  &         0.000        &        2.974    &        2.993     \\\\\n",
       "\\textbf{x1}    &       0.0192  &        0.005     &     3.595  &         0.000        &        0.009    &        0.030     \\\\\n",
       "\\textbf{x2}    &       0.1791  &        0.006     &    32.186  &         0.000        &        0.168    &        0.190     \\\\\n",
       "\\textbf{x3}    &       0.1491  &        0.006     &    24.069  &         0.000        &        0.137    &        0.161     \\\\\n",
       "\\textbf{x4}    &       0.0756  &        0.007     &    10.195  &         0.000        &        0.061    &        0.090     \\\\\n",
       "\\textbf{x5}    &       0.0964  &        0.006     &    17.130  &         0.000        &        0.085    &        0.107     \\\\\n",
       "\\textbf{x6}    &       0.1863  &        0.006     &    29.529  &         0.000        &        0.174    &        0.199     \\\\\n",
       "\\textbf{x7}    &       0.0551  &        0.008     &     7.020  &         0.000        &        0.040    &        0.070     \\\\\n",
       "\\textbf{x8}    &       0.0528  &        0.006     &     9.275  &         0.000        &        0.042    &        0.064     \\\\\n",
       "\\textbf{x9}    &       0.2046  &        0.006     &    31.675  &         0.000        &        0.192    &        0.217     \\\\\n",
       "\\textbf{x10}   &       0.0198  &        0.008     &     2.455  &         0.014        &        0.004    &        0.036     \\\\\n",
       "\\textbf{x11}   &       0.0521  &        0.006     &     9.042  &         0.000        &        0.041    &        0.063     \\\\\n",
       "\\textbf{x12}   &       0.2208  &        0.007     &    33.180  &         0.000        &        0.208    &        0.234     \\\\\n",
       "\\textbf{x13}   &      -0.0309  &        0.008     &    -3.759  &         0.000        &       -0.047    &       -0.015     \\\\\n",
       "\\textbf{x14}   &       0.0518  &        0.006     &     9.021  &         0.000        &        0.041    &        0.063     \\\\\n",
       "\\textbf{x15}   &       0.2336  &        0.007     &    34.640  &         0.000        &        0.220    &        0.247     \\\\\n",
       "\\textbf{x16}   &      -0.0826  &        0.008     &   -10.284  &         0.000        &       -0.098    &       -0.067     \\\\\n",
       "\\textbf{x17}   &       0.0032  &        0.006     &     0.567  &         0.571        &       -0.008    &        0.014     \\\\\n",
       "\\textbf{x18}   &       0.2296  &        0.007     &    33.537  &         0.000        &        0.216    &        0.243     \\\\\n",
       "\\textbf{x19}   &      -0.1758  &        0.008     &   -23.129  &         0.000        &       -0.191    &       -0.161     \\\\\n",
       "\\textbf{x20}   &      -0.0481  &        0.006     &    -8.620  &         0.000        &       -0.059    &       -0.037     \\\\\n",
       "\\textbf{x21}   &       0.2365  &        0.007     &    34.988  &         0.000        &        0.223    &        0.250     \\\\\n",
       "\\textbf{x22}   &      -0.2995  &        0.007     &   -41.807  &         0.000        &       -0.314    &       -0.285     \\\\\n",
       "\\textbf{x23}   &      -0.1055  &        0.006     &   -18.720  &         0.000        &       -0.117    &       -0.094     \\\\\n",
       "\\textbf{x24}   &       0.1825  &        0.006     &    29.593  &         0.000        &        0.170    &        0.195     \\\\\n",
       "\\textbf{x25}   &      -0.2728  &        0.006     &   -42.712  &         0.000        &       -0.285    &       -0.260     \\\\\n",
       "\\textbf{x26}   &      -0.0588  &        0.006     &   -10.108  &         0.000        &       -0.070    &       -0.047     \\\\\n",
       "\\textbf{x27}   &       0.2347  &        0.007     &    36.059  &         0.000        &        0.222    &        0.248     \\\\\n",
       "\\textbf{x28}   &      -0.1805  &        0.007     &   -27.321  &         0.000        &       -0.193    &       -0.168     \\\\\n",
       "\\textbf{x29}   &      -0.0078  &        0.006     &    -1.310  &         0.190        &       -0.020    &        0.004     \\\\\n",
       "\\textbf{x30}   &       0.2556  &        0.007     &    38.586  &         0.000        &        0.243    &        0.269     \\\\\n",
       "\\textbf{x31}   &      -0.1249  &        0.006     &   -19.875  &         0.000        &       -0.137    &       -0.113     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1492.045 & \\textbf{  Durbin-Watson:     } &     2.001  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } &   779.935  \\\\\n",
       "\\textbf{Skew:}          &   0.072  & \\textbf{  Prob(JB):          } & 4.36e-170  \\\\\n",
       "\\textbf{Kurtosis:}      &   2.454  & \\textbf{  Cond. No.          } &      4.14  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Class   R-squared:                       0.272\n",
       "Model:                            OLS   Adj. R-squared:                  0.271\n",
       "Method:                 Least Squares   F-statistic:                     704.6\n",
       "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
       "Time:                        11:57:53   Log-Likelihood:                -94420.\n",
       "No. Observations:               58571   AIC:                         1.889e+05\n",
       "Df Residuals:                   58539   BIC:                         1.892e+05\n",
       "Df Model:                          31                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.9837      0.005    595.114      0.000       2.974       2.993\n",
       "x1             0.0192      0.005      3.595      0.000       0.009       0.030\n",
       "x2             0.1791      0.006     32.186      0.000       0.168       0.190\n",
       "x3             0.1491      0.006     24.069      0.000       0.137       0.161\n",
       "x4             0.0756      0.007     10.195      0.000       0.061       0.090\n",
       "x5             0.0964      0.006     17.130      0.000       0.085       0.107\n",
       "x6             0.1863      0.006     29.529      0.000       0.174       0.199\n",
       "x7             0.0551      0.008      7.020      0.000       0.040       0.070\n",
       "x8             0.0528      0.006      9.275      0.000       0.042       0.064\n",
       "x9             0.2046      0.006     31.675      0.000       0.192       0.217\n",
       "x10            0.0198      0.008      2.455      0.014       0.004       0.036\n",
       "x11            0.0521      0.006      9.042      0.000       0.041       0.063\n",
       "x12            0.2208      0.007     33.180      0.000       0.208       0.234\n",
       "x13           -0.0309      0.008     -3.759      0.000      -0.047      -0.015\n",
       "x14            0.0518      0.006      9.021      0.000       0.041       0.063\n",
       "x15            0.2336      0.007     34.640      0.000       0.220       0.247\n",
       "x16           -0.0826      0.008    -10.284      0.000      -0.098      -0.067\n",
       "x17            0.0032      0.006      0.567      0.571      -0.008       0.014\n",
       "x18            0.2296      0.007     33.537      0.000       0.216       0.243\n",
       "x19           -0.1758      0.008    -23.129      0.000      -0.191      -0.161\n",
       "x20           -0.0481      0.006     -8.620      0.000      -0.059      -0.037\n",
       "x21            0.2365      0.007     34.988      0.000       0.223       0.250\n",
       "x22           -0.2995      0.007    -41.807      0.000      -0.314      -0.285\n",
       "x23           -0.1055      0.006    -18.720      0.000      -0.117      -0.094\n",
       "x24            0.1825      0.006     29.593      0.000       0.170       0.195\n",
       "x25           -0.2728      0.006    -42.712      0.000      -0.285      -0.260\n",
       "x26           -0.0588      0.006    -10.108      0.000      -0.070      -0.047\n",
       "x27            0.2347      0.007     36.059      0.000       0.222       0.248\n",
       "x28           -0.1805      0.007    -27.321      0.000      -0.193      -0.168\n",
       "x29           -0.0078      0.006     -1.310      0.190      -0.020       0.004\n",
       "x30            0.2556      0.007     38.586      0.000       0.243       0.269\n",
       "x31           -0.1249      0.006    -19.875      0.000      -0.137      -0.113\n",
       "==============================================================================\n",
       "Omnibus:                     1492.045   Durbin-Watson:                   2.001\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              779.935\n",
       "Skew:                           0.072   Prob(JB):                    4.36e-170\n",
       "Kurtosis:                       2.454   Cond. No.                         4.14\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = add_constant(Xt_train)\n",
    "mdl=OLS(y_train,X_tr, hasconst=12).fit()\n",
    "mdl.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19852e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: The same for Lasso, Ridge aand Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead9903",
   "metadata": {},
   "source": [
    "# 4) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8723e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy score is:  0.5122413439868879\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "      <th>Class 4</th>\n",
       "      <th>Class 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Class 1</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class 2</th>\n",
       "      <td>0</td>\n",
       "      <td>3143</td>\n",
       "      <td>98</td>\n",
       "      <td>80</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class 3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4094</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class 4</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>3158</td>\n",
       "      <td>409</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class 5</th>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "      <td>550</td>\n",
       "      <td>466</td>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Class 1  Class 2  Class 3  Class 4  Class 5\n",
       "Class 1        0        9     4063        0        0\n",
       "Class 2        0     3143       98       80      391\n",
       "Class 3        0        3     4094       18        0\n",
       "Class 4        0       68     3158      409       69\n",
       "Class 5        0      550      550      466     2355"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to CategoricalNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create a Categorical Naive Bayes Model with the scaled data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m cnb\u001b[38;5;241m=\u001b[39mCategoricalNB()\n\u001b[1;32m---> 18\u001b[0m cnb\u001b[38;5;241m.\u001b[39mfit(Xt_train,y_train)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Present the Results\u001b[39;00m\n\u001b[0;32m     21\u001b[0m preds\u001b[38;5;241m=\u001b[39mcnb\u001b[38;5;241m.\u001b[39mpredict(Xt_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:1391\u001b[0m, in \u001b[0;36mCategoricalNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:745\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    746\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    748\u001b[0m     labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:1452\u001b[0m, in \u001b[0;36mCategoricalNB._check_X_y\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m   1448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1449\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1450\u001b[0m         X, y, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reset\u001b[38;5;241m=\u001b[39mreset\n\u001b[0;32m   1451\u001b[0m     )\n\u001b[1;32m-> 1452\u001b[0m     check_non_negative(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategoricalNB (input X)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1490\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to CategoricalNB (input X)"
     ]
    }
   ],
   "source": [
    "#Column Names (a.k.a Possible Classes)\n",
    "classes = np.array(['Class 1','Class 2','Class 3','Class 4','Class 5'])\n",
    "\n",
    "# Create a Gaussian Naive Bayes Model with the scaled data\n",
    "gnb=GaussianNB()\n",
    "gnb.fit(Xt_train, y_train)\n",
    "\n",
    "# Present the Results\n",
    "preds=gnb.predict(Xt_test)\n",
    "print(\"The Accuracy score is: \", accuracy_score(y_test, preds))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "display(pd.DataFrame(confusion_matrix(y_test, preds), columns=classes, index=classes))\n",
    "\n",
    "\n",
    "# Create a Categorical Naive Bayes Model with the scaled data\n",
    "cnb=CategoricalNB()\n",
    "cnb.fit(Xt_train,y_train)\n",
    "\n",
    "# Present the Results\n",
    "preds=cnb.predict(Xt_test)\n",
    "print(\"The Accuracy score is: \", accuracy_score(y_test, preds))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "display(pd.DataFrame(confusion_matrix(y_test, preds), columns=classes, index=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf82ac",
   "metadata": {},
   "source": [
    "# 5) K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b65b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9469883220651506\n"
     ]
    }
   ],
   "source": [
    "# Scale the data so it can be used in K-Nearest Neighbours Models\n",
    "# scaler = StandardScaler() #Maybe use different Scalers (See info in TP06)\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(Xt_train, y_train)\n",
    "\n",
    "preds = knn.predict(Xt_test)\n",
    "\n",
    "# Present the Results\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#Sholud try to make plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5da97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
