{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae580f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "Postures = pd.read_csv(\"Postures.csv\")\n",
    "\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(y_test, preds,average='micro'))\n",
    "    print(\"The Recall is: %7.4f\"    % recall_score(y_test, preds,average='micro'))\n",
    "    print(\"The F1 score is: %7.4f\"  % f1_score(y_test, preds,average='micro'))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, preds))\n",
    "    print()\n",
    "    print(\"This is the Confusion Matrix\")\n",
    "    display(pd.DataFrame(confusion_matrix(truth, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad08a3",
   "metadata": {},
   "source": [
    "# 1) Processing the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f563055-6902-49bf-8c0d-f1f9cab49677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of missing values in column X3: 0.88%\n",
      "Proportion of missing values in column Y3: 0.88%\n",
      "Proportion of missing values in column Z3: 0.88%\n",
      "Proportion of missing values in column X4: 4.0%\n",
      "Proportion of missing values in column Y4: 4.0%\n",
      "Proportion of missing values in column Z4: 4.0%\n",
      "Proportion of missing values in column X5: 16.68%\n",
      "Proportion of missing values in column Y5: 16.68%\n",
      "Proportion of missing values in column Z5: 16.68%\n",
      "Proportion of missing values in column X6: 33.1%\n",
      "Proportion of missing values in column Y6: 33.1%\n",
      "Proportion of missing values in column Z6: 33.1%\n",
      "Proportion of missing values in column X7: 50.13%\n",
      "Proportion of missing values in column Y7: 50.13%\n",
      "Proportion of missing values in column Z7: 50.13%\n",
      "Proportion of missing values in column X8: 60.86%\n",
      "Proportion of missing values in column Y8: 60.86%\n",
      "Proportion of missing values in column Z8: 60.86%\n",
      "Proportion of missing values in column X9: 69.31%\n",
      "Proportion of missing values in column Y9: 69.31%\n",
      "Proportion of missing values in column Z9: 69.31%\n",
      "Proportion of missing values in column X10: 81.11%\n",
      "Proportion of missing values in column Y10: 81.11%\n",
      "Proportion of missing values in column Z10: 81.11%\n",
      "Proportion of missing values in column X11: 99.96%\n",
      "Proportion of missing values in column Y11: 99.96%\n",
      "Proportion of missing values in column Z11: 99.96%\n"
     ]
    }
   ],
   "source": [
    "# Eliminate first instance of Postures (all 0's) \n",
    "df = Postures.iloc[1:]\n",
    "\n",
    "for col in df.columns:\n",
    "    proportion = (df[col] == '?').mean()*100\n",
    "    if proportion > 0:\n",
    "        print(f'Proportion of missing values in column {col}: {round(proportion,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51b632e-8132-4b0f-85bf-3525bb2a9025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing the variables with a proportion of missing values more than 80% \n",
    "for col in df.columns:\n",
    "    proportion = (df[col] == '?').mean()*100\n",
    "    if proportion > 80:\n",
    "        df=df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb576599",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing the variables with a proportion of missing values more than 80% \n",
    "for col in df.columns:\n",
    "    proportion = (df[col] == '?').mean()*100\n",
    "    if proportion > 80:\n",
    "        df=df.drop(col, axis=1)\n",
    "        \n",
    "# Replace all '?' to NaN, so that the values are valid for Imputation\n",
    "for col in df.columns:\n",
    "    df.loc[df[col] == '?', col] = np.nan\n",
    "        \n",
    "X= df.drop(columns =[ 'Class' ]) \n",
    "y=df['Class']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b51109-7c90-42a2-9f74-01f19fb36a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the whole Set into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f27978-308b-45b1-84aa-98b6132b0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler   = PowerTransformer()\n",
    "scaler.fit(X_train)\n",
    "Xt_train = scaler.transform(X_train)\n",
    "Xt_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96962d37-3b87-4097-9d9b-a93d0debda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate a Simple Imputater\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    \n",
    "# Acquire a new DataFrame with Imputated Values\n",
    "imputer.fit(Xt_train)\n",
    "Xt_train = imputer.transform(Xt_train)\n",
    "Xt_test  = imputer.transform(Xt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bb377",
   "metadata": {},
   "source": [
    "# 2) Tree Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54e18f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "The Precision is:  0.8804\n",
      "The Recall is:  0.8804\n",
      "The F1 score is:  0.8804\n",
      "The Matthews correlation coefficient is:  0.8510\n",
      "\n",
      "This is the Confusion Matrix\n",
      "      0     1     2     3     4\n",
      "0  4041     5     9    16     1\n",
      "1     5  3404    23    60   220\n",
      "2   207     6  3435   436    31\n",
      "3    34    19   405  3181    65\n",
      "4   116   293    85   300  3127\n",
      "Cross-validated Accuracy: 0.8786087817408952\n",
      "Execution time: 69.6269166469574 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a Decision Tree Model with the data\n",
    "tree_mdl = DecisionTreeClassifier()\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV (taking ~53 seconds)\n",
    "parameters = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(tree_mdl, parameters, scoring='accuracy', cv=5)\n",
    "grid_search.fit(Xt_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best hyperparameters to create the final model\n",
    "final_tree_mdl = DecisionTreeClassifier(**best_params)\n",
    "final_tree_mdl.fit(Xt_train, y_train)\n",
    "preds = final_tree_mdl.predict(Xt_test)\n",
    "\n",
    "# Evaluate the results\n",
    "print(\"The Precision is: %7.4f\" % precision_score(y_test, preds, average='micro'))\n",
    "print(\"The Recall is: %7.4f\" % recall_score(y_test, preds, average='micro'))\n",
    "print(\"The F1 score is: %7.4f\" % f1_score(y_test, preds, average='micro'))\n",
    "print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, preds))\n",
    "print()\n",
    "print(\"This is the Confusion Matrix\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, preds)))\n",
    "\n",
    "# Cross-validated accuracy\n",
    "cv_accuracy = cross_val_score(final_tree_mdl, Xt_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Accuracy:\", np.mean(cv_accuracy))\n",
    "\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29e0ba",
   "metadata": {},
   "source": [
    "# 3) Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd812d93-0eaa-40f5-b289-a2169acc4f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bias is:  -0.46798649582440655\n",
      "The other parameters are: \n",
      "\t B01 ->    -0.032\n",
      "\t B02 ->    -0.991\n",
      "\t B03 ->    -1.123\n",
      "\t B04 ->    -0.517\n",
      "\t B05 ->    -0.833\n",
      "\t B06 ->    -1.188\n",
      "\t B07 ->    -0.448\n",
      "\t B08 ->    -0.754\n",
      "\t B09 ->    -1.262\n",
      "\t B10 ->    -0.231\n",
      "\t B11 ->    -0.733\n",
      "\t B12 ->    -1.419\n",
      "\t B13 ->     0.053\n",
      "\t B14 ->    -0.704\n",
      "\t B15 ->    -1.421\n",
      "\t B16 ->     0.092\n",
      "\t B17 ->    -0.641\n",
      "\t B18 ->    -1.595\n",
      "\t B19 ->     0.400\n",
      "\t B20 ->    -0.409\n",
      "\t B21 ->    -1.493\n",
      "\t B22 ->     0.738\n",
      "\t B23 ->    -0.127\n",
      "\t B24 ->    -0.547\n",
      "\t B25 ->     0.278\n",
      "\t B26 ->     0.340\n",
      "\t B27 ->    -0.711\n",
      "\t B28 ->     0.111\n",
      "\t B29 ->     0.612\n",
      "\t B30 ->    -0.562\n",
      "\t B31 ->     0.119\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression Model with the data\n",
    "LR = LogisticRegression(random_state=0).fit(Xt_train, y_train)\n",
    "\n",
    "# Present the Bias and the Betas\n",
    "print(\"The bias is: \",  LR.intercept_[0])\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(LR.coef_[0]):\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a18cd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Class</td>      <th>  R-squared:         </th> <td>   0.274</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.273</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   711.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 19 Nov 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:17:38</td>     <th>  Log-Likelihood:    </th> <td> -94342.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 58571</td>      <th>  AIC:               </th> <td>1.887e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 58539</td>      <th>  BIC:               </th> <td>1.890e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    31</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.9837</td> <td>    0.005</td> <td>  595.911</td> <td> 0.000</td> <td>    2.974</td> <td>    2.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0062</td> <td>    0.005</td> <td>   -1.163</td> <td> 0.245</td> <td>   -0.017</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1826</td> <td>    0.006</td> <td>   32.846</td> <td> 0.000</td> <td>    0.172</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1527</td> <td>    0.006</td> <td>   24.684</td> <td> 0.000</td> <td>    0.141</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0811</td> <td>    0.007</td> <td>   10.943</td> <td> 0.000</td> <td>    0.067</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.1020</td> <td>    0.006</td> <td>   18.138</td> <td> 0.000</td> <td>    0.091</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.1864</td> <td>    0.006</td> <td>   29.574</td> <td> 0.000</td> <td>    0.174</td> <td>    0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0670</td> <td>    0.008</td> <td>    8.543</td> <td> 0.000</td> <td>    0.052</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0594</td> <td>    0.006</td> <td>   10.437</td> <td> 0.000</td> <td>    0.048</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.2052</td> <td>    0.006</td> <td>   31.806</td> <td> 0.000</td> <td>    0.193</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0364</td> <td>    0.008</td> <td>    4.517</td> <td> 0.000</td> <td>    0.021</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0568</td> <td>    0.006</td> <td>    9.830</td> <td> 0.000</td> <td>    0.046</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.2234</td> <td>    0.007</td> <td>   33.473</td> <td> 0.000</td> <td>    0.210</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0166</td> <td>    0.008</td> <td>   -2.010</td> <td> 0.044</td> <td>   -0.033</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0560</td> <td>    0.006</td> <td>    9.560</td> <td> 0.000</td> <td>    0.044</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.2431</td> <td>    0.007</td> <td>   35.476</td> <td> 0.000</td> <td>    0.230</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0750</td> <td>    0.008</td> <td>   -9.164</td> <td> 0.000</td> <td>   -0.091</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0012</td> <td>    0.006</td> <td>    0.194</td> <td> 0.846</td> <td>   -0.011</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.2520</td> <td>    0.007</td> <td>   34.012</td> <td> 0.000</td> <td>    0.238</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.1863</td> <td>    0.008</td> <td>  -22.509</td> <td> 0.000</td> <td>   -0.203</td> <td>   -0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.0678</td> <td>    0.007</td> <td>   -9.988</td> <td> 0.000</td> <td>   -0.081</td> <td>   -0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.2636</td> <td>    0.008</td> <td>   32.289</td> <td> 0.000</td> <td>    0.248</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.3379</td> <td>    0.009</td> <td>  -38.695</td> <td> 0.000</td> <td>   -0.355</td> <td>   -0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   -0.1695</td> <td>    0.008</td> <td>  -21.531</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.2168</td> <td>    0.009</td> <td>   24.997</td> <td> 0.000</td> <td>    0.200</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -0.3548</td> <td>    0.009</td> <td>  -39.341</td> <td> 0.000</td> <td>   -0.372</td> <td>   -0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.1292</td> <td>    0.009</td> <td>  -14.214</td> <td> 0.000</td> <td>   -0.147</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.3673</td> <td>    0.010</td> <td>   35.237</td> <td> 0.000</td> <td>    0.347</td> <td>    0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   -0.3044</td> <td>    0.010</td> <td>  -29.265</td> <td> 0.000</td> <td>   -0.325</td> <td>   -0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -0.0441</td> <td>    0.011</td> <td>   -4.173</td> <td> 0.000</td> <td>   -0.065</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.4861</td> <td>    0.012</td> <td>   41.022</td> <td> 0.000</td> <td>    0.463</td> <td>    0.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -0.2818</td> <td>    0.011</td> <td>  -25.293</td> <td> 0.000</td> <td>   -0.304</td> <td>   -0.260</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>455.843</td> <th>  Durbin-Watson:     </th> <td>   2.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 367.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.122</td>  <th>  Prob(JB):          </th> <td>1.45e-80</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.698</td>  <th>  Cond. No.          </th> <td>    5.67</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Class       & \\textbf{  R-squared:         } &     0.274   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.273   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     711.5   \\\\\n",
       "\\textbf{Date:}             & Sun, 19 Nov 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     17:17:38     & \\textbf{  Log-Likelihood:    } &   -94342.   \\\\\n",
       "\\textbf{No. Observations:} &       58571      & \\textbf{  AIC:               } & 1.887e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &       58539      & \\textbf{  BIC:               } & 1.890e+05   \\\\\n",
       "\\textbf{Df Model:}         &          31      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       2.9837  &        0.005     &   595.911  &         0.000        &        2.974    &        2.993     \\\\\n",
       "\\textbf{x1}    &      -0.0062  &        0.005     &    -1.163  &         0.245        &       -0.017    &        0.004     \\\\\n",
       "\\textbf{x2}    &       0.1826  &        0.006     &    32.846  &         0.000        &        0.172    &        0.193     \\\\\n",
       "\\textbf{x3}    &       0.1527  &        0.006     &    24.684  &         0.000        &        0.141    &        0.165     \\\\\n",
       "\\textbf{x4}    &       0.0811  &        0.007     &    10.943  &         0.000        &        0.067    &        0.096     \\\\\n",
       "\\textbf{x5}    &       0.1020  &        0.006     &    18.138  &         0.000        &        0.091    &        0.113     \\\\\n",
       "\\textbf{x6}    &       0.1864  &        0.006     &    29.574  &         0.000        &        0.174    &        0.199     \\\\\n",
       "\\textbf{x7}    &       0.0670  &        0.008     &     8.543  &         0.000        &        0.052    &        0.082     \\\\\n",
       "\\textbf{x8}    &       0.0594  &        0.006     &    10.437  &         0.000        &        0.048    &        0.071     \\\\\n",
       "\\textbf{x9}    &       0.2052  &        0.006     &    31.806  &         0.000        &        0.193    &        0.218     \\\\\n",
       "\\textbf{x10}   &       0.0364  &        0.008     &     4.517  &         0.000        &        0.021    &        0.052     \\\\\n",
       "\\textbf{x11}   &       0.0568  &        0.006     &     9.830  &         0.000        &        0.046    &        0.068     \\\\\n",
       "\\textbf{x12}   &       0.2234  &        0.007     &    33.473  &         0.000        &        0.210    &        0.237     \\\\\n",
       "\\textbf{x13}   &      -0.0166  &        0.008     &    -2.010  &         0.044        &       -0.033    &       -0.000     \\\\\n",
       "\\textbf{x14}   &       0.0560  &        0.006     &     9.560  &         0.000        &        0.044    &        0.067     \\\\\n",
       "\\textbf{x15}   &       0.2431  &        0.007     &    35.476  &         0.000        &        0.230    &        0.257     \\\\\n",
       "\\textbf{x16}   &      -0.0750  &        0.008     &    -9.164  &         0.000        &       -0.091    &       -0.059     \\\\\n",
       "\\textbf{x17}   &       0.0012  &        0.006     &     0.194  &         0.846        &       -0.011    &        0.013     \\\\\n",
       "\\textbf{x18}   &       0.2520  &        0.007     &    34.012  &         0.000        &        0.238    &        0.267     \\\\\n",
       "\\textbf{x19}   &      -0.1863  &        0.008     &   -22.509  &         0.000        &       -0.203    &       -0.170     \\\\\n",
       "\\textbf{x20}   &      -0.0678  &        0.007     &    -9.988  &         0.000        &       -0.081    &       -0.054     \\\\\n",
       "\\textbf{x21}   &       0.2636  &        0.008     &    32.289  &         0.000        &        0.248    &        0.280     \\\\\n",
       "\\textbf{x22}   &      -0.3379  &        0.009     &   -38.695  &         0.000        &       -0.355    &       -0.321     \\\\\n",
       "\\textbf{x23}   &      -0.1695  &        0.008     &   -21.531  &         0.000        &       -0.185    &       -0.154     \\\\\n",
       "\\textbf{x24}   &       0.2168  &        0.009     &    24.997  &         0.000        &        0.200    &        0.234     \\\\\n",
       "\\textbf{x25}   &      -0.3548  &        0.009     &   -39.341  &         0.000        &       -0.372    &       -0.337     \\\\\n",
       "\\textbf{x26}   &      -0.1292  &        0.009     &   -14.214  &         0.000        &       -0.147    &       -0.111     \\\\\n",
       "\\textbf{x27}   &       0.3673  &        0.010     &    35.237  &         0.000        &        0.347    &        0.388     \\\\\n",
       "\\textbf{x28}   &      -0.3044  &        0.010     &   -29.265  &         0.000        &       -0.325    &       -0.284     \\\\\n",
       "\\textbf{x29}   &      -0.0441  &        0.011     &    -4.173  &         0.000        &       -0.065    &       -0.023     \\\\\n",
       "\\textbf{x30}   &       0.4861  &        0.012     &    41.022  &         0.000        &        0.463    &        0.509     \\\\\n",
       "\\textbf{x31}   &      -0.2818  &        0.011     &   -25.293  &         0.000        &       -0.304    &       -0.260     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 455.843 & \\textbf{  Durbin-Watson:     } &    2.001  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  367.666  \\\\\n",
       "\\textbf{Skew:}          &   0.122 & \\textbf{  Prob(JB):          } & 1.45e-80  \\\\\n",
       "\\textbf{Kurtosis:}      &   2.698 & \\textbf{  Cond. No.          } &     5.67  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Class   R-squared:                       0.274\n",
       "Model:                            OLS   Adj. R-squared:                  0.273\n",
       "Method:                 Least Squares   F-statistic:                     711.5\n",
       "Date:                Sun, 19 Nov 2023   Prob (F-statistic):               0.00\n",
       "Time:                        17:17:38   Log-Likelihood:                -94342.\n",
       "No. Observations:               58571   AIC:                         1.887e+05\n",
       "Df Residuals:                   58539   BIC:                         1.890e+05\n",
       "Df Model:                          31                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.9837      0.005    595.911      0.000       2.974       2.993\n",
       "x1            -0.0062      0.005     -1.163      0.245      -0.017       0.004\n",
       "x2             0.1826      0.006     32.846      0.000       0.172       0.193\n",
       "x3             0.1527      0.006     24.684      0.000       0.141       0.165\n",
       "x4             0.0811      0.007     10.943      0.000       0.067       0.096\n",
       "x5             0.1020      0.006     18.138      0.000       0.091       0.113\n",
       "x6             0.1864      0.006     29.574      0.000       0.174       0.199\n",
       "x7             0.0670      0.008      8.543      0.000       0.052       0.082\n",
       "x8             0.0594      0.006     10.437      0.000       0.048       0.071\n",
       "x9             0.2052      0.006     31.806      0.000       0.193       0.218\n",
       "x10            0.0364      0.008      4.517      0.000       0.021       0.052\n",
       "x11            0.0568      0.006      9.830      0.000       0.046       0.068\n",
       "x12            0.2234      0.007     33.473      0.000       0.210       0.237\n",
       "x13           -0.0166      0.008     -2.010      0.044      -0.033      -0.000\n",
       "x14            0.0560      0.006      9.560      0.000       0.044       0.067\n",
       "x15            0.2431      0.007     35.476      0.000       0.230       0.257\n",
       "x16           -0.0750      0.008     -9.164      0.000      -0.091      -0.059\n",
       "x17            0.0012      0.006      0.194      0.846      -0.011       0.013\n",
       "x18            0.2520      0.007     34.012      0.000       0.238       0.267\n",
       "x19           -0.1863      0.008    -22.509      0.000      -0.203      -0.170\n",
       "x20           -0.0678      0.007     -9.988      0.000      -0.081      -0.054\n",
       "x21            0.2636      0.008     32.289      0.000       0.248       0.280\n",
       "x22           -0.3379      0.009    -38.695      0.000      -0.355      -0.321\n",
       "x23           -0.1695      0.008    -21.531      0.000      -0.185      -0.154\n",
       "x24            0.2168      0.009     24.997      0.000       0.200       0.234\n",
       "x25           -0.3548      0.009    -39.341      0.000      -0.372      -0.337\n",
       "x26           -0.1292      0.009    -14.214      0.000      -0.147      -0.111\n",
       "x27            0.3673      0.010     35.237      0.000       0.347       0.388\n",
       "x28           -0.3044      0.010    -29.265      0.000      -0.325      -0.284\n",
       "x29           -0.0441      0.011     -4.173      0.000      -0.065      -0.023\n",
       "x30            0.4861      0.012     41.022      0.000       0.463       0.509\n",
       "x31           -0.2818      0.011    -25.293      0.000      -0.304      -0.260\n",
       "==============================================================================\n",
       "Omnibus:                      455.843   Durbin-Watson:                   2.001\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              367.666\n",
       "Skew:                           0.122   Prob(JB):                     1.45e-80\n",
       "Kurtosis:                       2.698   Cond. No.                         5.67\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = add_constant(Xt_train)\n",
    "mdl=OLS(y_train,X_tr, hasconst=12).fit()\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "656cc49b-be98-4cf7-9840-ec95c43bb801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t B18 ->     1.595\n",
      "\t B21 ->     1.493\n",
      "\t B15 ->     1.421\n",
      "\t B12 ->     1.419\n",
      "\t B09 ->     1.262\n"
     ]
    }
   ],
   "source": [
    "coefs=[(abs(beta),i) for i, beta in enumerate(LR.coef_[0])]\n",
    "coefs.sort()\n",
    "coefs.reverse()\n",
    "for beta, i in coefs[:5]:\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7901a81-d428-4f09-8d10-c88e26b5dc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.7707\n",
      "The Precision is:  0.7707\n",
      "The Recall is:  0.7707\n",
      "The F1 score is:  0.7707\n",
      "The Matthews correlation coefficient is:  0.7136\n",
      "\n",
      "This is the Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3508</td>\n",
       "      <td>9</td>\n",
       "      <td>252</td>\n",
       "      <td>164</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>3270</td>\n",
       "      <td>58</td>\n",
       "      <td>76</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390</td>\n",
       "      <td>7</td>\n",
       "      <td>3133</td>\n",
       "      <td>515</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266</td>\n",
       "      <td>188</td>\n",
       "      <td>486</td>\n",
       "      <td>2359</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123</td>\n",
       "      <td>495</td>\n",
       "      <td>125</td>\n",
       "      <td>400</td>\n",
       "      <td>2778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4\n",
       "0  3508     9   252   164   139\n",
       "1    40  3270    58    76   268\n",
       "2   390     7  3133   515    70\n",
       "3   266   188   486  2359   405\n",
       "4   123   495   125   400  2778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the Results\n",
    "preds = LR.predict(Xt_test)\n",
    "printClassResults(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "304265b6-0e3e-4e5e-a65d-68106a13db34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bias is:  -0.5836506120776492\n",
      "The other parameters are: \n",
      "\t B01 ->     0.003\n",
      "\t B02 ->    -0.191\n",
      "\t B03 ->    -0.141\n",
      "\t B04 ->    -0.116\n",
      "\t B05 ->    -0.140\n",
      "\t B06 ->    -0.145\n",
      "\t B07 ->    -0.086\n",
      "\t B08 ->    -0.109\n",
      "\t B09 ->    -0.133\n",
      "\t B10 ->    -0.056\n",
      "\t B11 ->    -0.099\n",
      "\t B12 ->    -0.144\n",
      "\t B13 ->    -0.014\n",
      "\t B14 ->    -0.082\n",
      "\t B15 ->    -0.133\n",
      "\t B16 ->    -0.001\n",
      "\t B17 ->    -0.042\n",
      "\t B18 ->    -0.147\n",
      "\t B19 ->     0.046\n",
      "\t B20 ->     0.006\n",
      "\t B21 ->    -0.152\n",
      "\t B22 ->     0.121\n",
      "\t B23 ->     0.025\n",
      "\t B24 ->    -0.077\n",
      "\t B25 ->     0.080\n",
      "\t B26 ->     0.019\n",
      "\t B27 ->    -0.140\n",
      "\t B28 ->     0.034\n",
      "\t B29 ->     0.005\n",
      "\t B30 ->    -0.131\n",
      "\t B31 ->     0.003\n"
     ]
    }
   ],
   "source": [
    "# Create a Ridge Classifier Model with the data\n",
    "RC = RidgeClassifier(random_state=0).fit(Xt_train, y_train)\n",
    "\n",
    "# Present the Bias and the Betas\n",
    "print(\"The bias is: \",  RC.intercept_[0])\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(RC.coef_[0]):\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "802b2c39-abb0-4747-abe7-0e2ec1d36a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t B02 ->     0.191\n",
      "\t B21 ->     0.152\n",
      "\t B18 ->     0.147\n",
      "\t B06 ->     0.145\n",
      "\t B12 ->     0.144\n"
     ]
    }
   ],
   "source": [
    "coefs=[(abs(beta),i) for i, beta in enumerate(RC.coef_[0])]\n",
    "coefs.sort()\n",
    "coefs.reverse()\n",
    "for beta, i in coefs[:5]:\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a2356b-1b79-4335-aa1b-d189535ad9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.7214\n",
      "The Precision is:  0.7214\n",
      "The Recall is:  0.7214\n",
      "The F1 score is:  0.7214\n",
      "The Matthews correlation coefficient is:  0.6554\n",
      "\n",
      "This is the Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3711</td>\n",
       "      <td>53</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>3085</td>\n",
       "      <td>44</td>\n",
       "      <td>104</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>868</td>\n",
       "      <td>134</td>\n",
       "      <td>2742</td>\n",
       "      <td>314</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>407</td>\n",
       "      <td>442</td>\n",
       "      <td>627</td>\n",
       "      <td>1763</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>658</td>\n",
       "      <td>104</td>\n",
       "      <td>174</td>\n",
       "      <td>2784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4\n",
       "0  3711    53   150     1   157\n",
       "1    31  3085    44   104   448\n",
       "2   868   134  2742   314    57\n",
       "3   407   442   627  1763   465\n",
       "4   201   658   104   174  2784"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the Results\n",
    "preds = RC.predict(Xt_test)\n",
    "printClassResults(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19852e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: The same for Lasso, Ridge aand Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead9903",
   "metadata": {},
   "source": [
    "# 4) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8723e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy score is:  0.5098340503995082\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class 1</th>\n",
       "      <th>Class 2</th>\n",
       "      <th>Class 3</th>\n",
       "      <th>Class 4</th>\n",
       "      <th>Class 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Class 1</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class 2</th>\n",
       "      <td>0</td>\n",
       "      <td>3148</td>\n",
       "      <td>97</td>\n",
       "      <td>76</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class 3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4092</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class 4</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>3159</td>\n",
       "      <td>391</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class 5</th>\n",
       "      <td>0</td>\n",
       "      <td>568</td>\n",
       "      <td>550</td>\n",
       "      <td>480</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Class 1  Class 2  Class 3  Class 4  Class 5\n",
       "Class 1        0        9     4063        0        0\n",
       "Class 2        0     3148       97       76      391\n",
       "Class 3        0        4     4092       19        0\n",
       "Class 4        0      102     3159      391       52\n",
       "Class 5        0      568      550      480     2323"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to CategoricalNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create a Categorical Naive Bayes Model with the scaled data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m cnb\u001b[38;5;241m=\u001b[39mCategoricalNB()\n\u001b[1;32m---> 18\u001b[0m cnb\u001b[38;5;241m.\u001b[39mfit(Xt_train,y_train)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Present the Results\u001b[39;00m\n\u001b[0;32m     21\u001b[0m preds\u001b[38;5;241m=\u001b[39mcnb\u001b[38;5;241m.\u001b[39mpredict(Xt_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:1391\u001b[0m, in \u001b[0;36mCategoricalNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m   1368\u001b[0m \n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:745\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    746\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    748\u001b[0m     labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:1452\u001b[0m, in \u001b[0;36mCategoricalNB._check_X_y\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m   1448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1449\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1450\u001b[0m         X, y, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reset\u001b[38;5;241m=\u001b[39mreset\n\u001b[0;32m   1451\u001b[0m     )\n\u001b[1;32m-> 1452\u001b[0m     check_non_negative(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategoricalNB (input X)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1490\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmin(X)\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to CategoricalNB (input X)"
     ]
    }
   ],
   "source": [
    "#Column Names (a.k.a Possible Classes)\n",
    "classes = np.array(['Class 1','Class 2','Class 3','Class 4','Class 5'])\n",
    "\n",
    "# Create a Gaussian Naive Bayes Model with the scaled data\n",
    "gnb=GaussianNB()\n",
    "gnb.fit(Xt_train, y_train)\n",
    "\n",
    "# Present the Results\n",
    "preds=gnb.predict(Xt_test)\n",
    "print(\"The Accuracy score is: \", accuracy_score(y_test, preds))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "display(pd.DataFrame(confusion_matrix(y_test, preds), columns=classes, index=classes))\n",
    "\n",
    "\n",
    "# Create a Categorical Naive Bayes Model with the scaled data\n",
    "cnb=CategoricalNB()\n",
    "cnb.fit(Xt_train,y_train)\n",
    "\n",
    "# Present the Results\n",
    "preds=cnb.predict(Xt_test)\n",
    "print(\"The Accuracy score is: \", accuracy_score(y_test, preds))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "display(pd.DataFrame(confusion_matrix(y_test, preds), columns=classes, index=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf82ac",
   "metadata": {},
   "source": [
    "# 5) K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b65b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9383835279655808\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(Xt_train, y_train)\n",
    "\n",
    "preds = knn.predict(Xt_test)\n",
    "\n",
    "# Present the Results\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#Sholud try to make plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5da97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
