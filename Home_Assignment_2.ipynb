{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae580f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "Postures = pd.read_csv(\"Postures.csv\")\n",
    "\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(y_test, preds,average='micro'))\n",
    "    print(\"The Recall is: %7.4f\"    % recall_score(y_test, preds,average='micro'))\n",
    "    print(\"The F1 score is: %7.4f\"  % f1_score(y_test, preds,average='micro'))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(y_test, preds))\n",
    "    print()\n",
    "    print(\"This is the Confusion Matrix\")\n",
    "    display(pd.DataFrame(confusion_matrix(truth, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ad08a3",
   "metadata": {},
   "source": [
    "# 1) Processing the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f563055-6902-49bf-8c0d-f1f9cab49677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of missing values in column X3: 0.88%\n",
      "Proportion of missing values in column Y3: 0.88%\n",
      "Proportion of missing values in column Z3: 0.88%\n",
      "Proportion of missing values in column X4: 4.0%\n",
      "Proportion of missing values in column Y4: 4.0%\n",
      "Proportion of missing values in column Z4: 4.0%\n",
      "Proportion of missing values in column X5: 16.68%\n",
      "Proportion of missing values in column Y5: 16.68%\n",
      "Proportion of missing values in column Z5: 16.68%\n",
      "Proportion of missing values in column X6: 33.1%\n",
      "Proportion of missing values in column Y6: 33.1%\n",
      "Proportion of missing values in column Z6: 33.1%\n",
      "Proportion of missing values in column X7: 50.13%\n",
      "Proportion of missing values in column Y7: 50.13%\n",
      "Proportion of missing values in column Z7: 50.13%\n",
      "Proportion of missing values in column X8: 60.86%\n",
      "Proportion of missing values in column Y8: 60.86%\n",
      "Proportion of missing values in column Z8: 60.86%\n",
      "Proportion of missing values in column X9: 69.31%\n",
      "Proportion of missing values in column Y9: 69.31%\n",
      "Proportion of missing values in column Z9: 69.31%\n",
      "Proportion of missing values in column X10: 81.11%\n",
      "Proportion of missing values in column Y10: 81.11%\n",
      "Proportion of missing values in column Z10: 81.11%\n",
      "Proportion of missing values in column X11: 99.96%\n",
      "Proportion of missing values in column Y11: 99.96%\n",
      "Proportion of missing values in column Z11: 99.96%\n"
     ]
    }
   ],
   "source": [
    "# Eliminate first instance of Postures (all 0's) \n",
    "df = Postures.iloc[1:]\n",
    "\n",
    "for col in df.columns:\n",
    "    proportion = (df[col] == '?').mean()*100\n",
    "    if proportion > 0:\n",
    "        print(f'Proportion of missing values in column {col}: {round(proportion,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51b632e-8132-4b0f-85bf-3525bb2a9025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing the variables with a proportion of missing values more than 80% \n",
    "for col in df.columns:\n",
    "    proportion = (df[col] == '?').mean()*100\n",
    "    if proportion > 80:\n",
    "        df=df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb576599",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#removing the variables with a proportion of missing values more than 80% \n",
    "for col in df.columns:\n",
    "    proportion = (df[col] == '?').mean()*100\n",
    "    if proportion > 80:\n",
    "        df=df.drop(col, axis=1)\n",
    "        \n",
    "# Replace all '?' to NaN, so that the values are valid for Imputation\n",
    "for col in df.columns:\n",
    "    df.loc[df[col] == '?', col] = np.nan\n",
    "        \n",
    "X= df.drop(columns =[ 'Class' ]) \n",
    "y=df['Class']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b51109-7c90-42a2-9f74-01f19fb36a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the whole Set into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96962d37-3b87-4097-9d9b-a93d0debda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Simple Imputer (should come before scaling)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Acquire a new DataFrame with Imputed Values\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f27978-308b-45b1-84aa-98b6132b0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data using PowerTransformer\n",
    "scaler = PowerTransformer()\n",
    "scaler.fit(X_train_imputed)\n",
    "X_train_scaled = scaler.transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bb377",
   "metadata": {},
   "source": [
    "# 2) Tree Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e18f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 3}\n",
      "The Accuracy is:  0.8472\n",
      "The Precision is:  0.8472\n",
      "The Recall is:  0.8472\n",
      "The F1 score is:  0.8472\n",
      "The Matthews correlation coefficient is:  0.8101\n",
      "\n",
      "This is the Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4039</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>3350</td>\n",
       "      <td>35</td>\n",
       "      <td>109</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>515</td>\n",
       "      <td>20</td>\n",
       "      <td>3091</td>\n",
       "      <td>452</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>517</td>\n",
       "      <td>2986</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123</td>\n",
       "      <td>352</td>\n",
       "      <td>129</td>\n",
       "      <td>242</td>\n",
       "      <td>3075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4\n",
       "0  4039     8     9    15     1\n",
       "1     9  3350    35   109   209\n",
       "2   515    20  3091   452    37\n",
       "3    72    51   517  2986    78\n",
       "4   123   352   129   242  3075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Accuracy: 0.8410646500158748\n",
      "Execution time: 43.633217334747314 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Create a Decision Tree Model with the data\n",
    "tree_mdl = DecisionTreeClassifier()\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "parameters = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [5, 8],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(tree_mdl, parameters, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best hyperparameters to create the final model\n",
    "final_tree_mdl = DecisionTreeClassifier(**best_params)\n",
    "final_tree_mdl.fit(X_train_scaled, y_train)\n",
    "preds = final_tree_mdl.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the results\n",
    "printClassResults(y_test, preds)\n",
    "\n",
    "# Cross-validated accuracy\n",
    "cv_accuracy = cross_val_score(final_tree_mdl, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Accuracy:\", np.mean(cv_accuracy))\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29e0ba",
   "metadata": {},
   "source": [
    "# 3) Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd812d93-0eaa-40f5-b289-a2169acc4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model with the data\n",
    "LR = LogisticRegression(random_state=0).fit(Xt_train, y_train)\n",
    "\n",
    "# Present the Bias and the Betas\n",
    "print(\"The bias is: \",  LR.intercept_[0])\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(LR.coef_[0]):\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = add_constant(Xt_train)\n",
    "mdl=OLS(y_train,X_tr, hasconst=12).fit()\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cc49b-be98-4cf7-9840-ec95c43bb801",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs=[(abs(beta),i) for i, beta in enumerate(LR.coef_[0])]\n",
    "coefs.sort()\n",
    "coefs.reverse()\n",
    "for beta, i in coefs[:5]:\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7901a81-d428-4f09-8d10-c88e26b5dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Results\n",
    "preds = LR.predict(Xt_test)\n",
    "printClassResults(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304265b6-0e3e-4e5e-a65d-68106a13db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Ridge Classifier Model with the data\n",
    "RC = RidgeClassifier(random_state=0).fit(Xt_train, y_train)\n",
    "\n",
    "# Present the Bias and the Betas\n",
    "print(\"The bias is: \",  RC.intercept_[0])\n",
    "print(\"The other parameters are: \")\n",
    "for i, beta in enumerate(RC.coef_[0]):\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b2c39-abb0-4747-abe7-0e2ec1d36a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs=[(abs(beta),i) for i, beta in enumerate(RC.coef_[0])]\n",
    "coefs.sort()\n",
    "coefs.reverse()\n",
    "for beta, i in coefs[:5]:\n",
    "    print(\"\\t B%02d -> %9.3f\"% (i+1, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2356b-1b79-4335-aa1b-d189535ad9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Results\n",
    "preds = RC.predict(Xt_test)\n",
    "printClassResults(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19852e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: The same for Lasso, Ridge aand Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead9903",
   "metadata": {},
   "source": [
    "# 4) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column Names (a.k.a Possible Classes)\n",
    "classes = np.array(['Class 1','Class 2','Class 3','Class 4','Class 5'])\n",
    "\n",
    "# Create a Gaussian Naive Bayes Model with the scaled data\n",
    "gnb=GaussianNB()\n",
    "gnb.fit(Xt_train, y_train)\n",
    "\n",
    "# Present the Results\n",
    "preds=gnb.predict(Xt_test)\n",
    "print(\"The Accuracy score is: \", accuracy_score(y_test, preds))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "display(pd.DataFrame(confusion_matrix(y_test, preds), columns=classes, index=classes))\n",
    "\n",
    "\n",
    "# Create a Categorical Naive Bayes Model with the scaled data\n",
    "cnb=CategoricalNB()\n",
    "cnb.fit(Xt_train,y_train)\n",
    "\n",
    "# Present the Results\n",
    "preds=cnb.predict(Xt_test)\n",
    "print(\"The Accuracy score is: \", accuracy_score(y_test, preds))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "display(pd.DataFrame(confusion_matrix(y_test, preds), columns=classes, index=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf82ac",
   "metadata": {},
   "source": [
    "# 5) K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(Xt_train, y_train)\n",
    "\n",
    "preds = knn.predict(Xt_test)\n",
    "\n",
    "# Present the Results\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#Sholud try to make plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5da97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
